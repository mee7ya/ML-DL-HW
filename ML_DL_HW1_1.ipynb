{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import Uniform\n",
    "from sklearn.datasets import load_iris\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedAnnealing(torch.optim.Optimizer):\n",
    "    def __init__(self, params, init_T, annealing_rate, max_iter):\n",
    "        defaults = dict(init_T=init_T, annealing_rate=annealing_rate, max_iter=max_iter, T=init_T, total_iter=1)\n",
    "        super(SimulatedAnnealing, self).__init__(params, defaults)\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "            \n",
    "        dist = Normal(torch.tensor(0.0), torch.tensor(0.01))\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            group['iter'] = 1\n",
    "            while group['iter'] <= group['max_iter']:\n",
    "                init_T = group['init_T']\n",
    "                annealing_rate = group['annealing_rate']\n",
    "\n",
    "                best_params = [p.clone() for p in group['params']]\n",
    "\n",
    "                for p in group['params']:\n",
    "                    bias = dist.sample(p.data.size())\n",
    "                    p.data.add_(bias)\n",
    "\n",
    "                new_loss = closure()\n",
    "                if new_loss.item() <= loss.item():\n",
    "                    for p, pbkp in zip(group['params'], best_params):\n",
    "                        pbkp.data = p.data.clone()\n",
    "                    loss = new_loss.clone()\n",
    "                else:\n",
    "                    acceptance_p = torch.exp((loss - new_loss)/group['T'])\n",
    "                    if acceptance_p > Uniform(0, 1).sample(acceptance_p.size()):\n",
    "                        for p, pbkp in zip(group['params'], best_params):\n",
    "                            pbkp.data = p.data.clone()\n",
    "                        loss = new_loss.clone()\n",
    "                    else:\n",
    "                        for p, pbkp in zip(group['params'], best_params):\n",
    "                            p.data = pbkp.data.clone()\n",
    "                    group['T'] = group['init_T'] * annealing_rate / group['total_iter']\n",
    "                    group['iter'] += 1\n",
    "                    group['total_iter'] += 1\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading iris dataset using sklearn built-in feature\n",
    "iris = load_iris()\n",
    "x_data = iris.data\n",
    "y_data = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using one-hot encoding to convert integers to categorical data\n",
    "y_data = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from numpy data structure to pytorch's wrapper\n",
    "x_data = Variable(torch.from_numpy(x_data))\n",
    "y_data = Variable(torch.from_numpy(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.l1 = torch.nn.Linear(4, 12)\n",
    "        self.l2 = torch.nn.Linear(12, 16)\n",
    "        self.l3 = torch.nn.Linear(16, 3)\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "        self.relu=torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out1=self.relu(self.l1(x))\n",
    "        out2=self.relu(self.l2(out1))\n",
    "        y_pred=self.sigmoid(self.l3(out2))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=4, out_features=12, bias=True)\n",
       "  (l2): Linear(in_features=12, out_features=16, bias=True)\n",
       "  (l3): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting summary of a model\n",
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definining Binary Cross Entropy as a loss function\n",
    "loss_f = torch.nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up training parameters\n",
    "batch_size=16\n",
    "init_T=500\n",
    "annealing_rate=0.85\n",
    "max_iter = 100\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Simulated Annealing as an optimizer\n",
    "opt = SimulatedAnnealing(model.parameters(), init_T=init_T, annealing_rate=annealing_rate, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling data\n",
    "permutation = torch.randperm(x_data.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch: 0, loss: 0.6273958086967468\n",
      "Epoch: 0, batch: 16, loss: 0.6949339509010315\n",
      "Epoch: 0, batch: 32, loss: 0.6865144371986389\n",
      "Epoch: 0, batch: 48, loss: 0.7181211113929749\n",
      "Epoch: 0, batch: 64, loss: 1.1376310586929321\n",
      "Epoch: 0, batch: 80, loss: 1.2469877004623413\n",
      "Epoch: 0, batch: 96, loss: 0.7723749279975891\n",
      "Epoch: 0, batch: 112, loss: 0.7093414664268494\n",
      "Epoch: 0, batch: 128, loss: 0.9261996150016785\n",
      "Epoch: 0, batch: 144, loss: 1.1008186340332031\n",
      "Epoch: 1, batch: 0, loss: 1.3429183959960938\n",
      "Epoch: 1, batch: 16, loss: 1.2605472803115845\n",
      "Epoch: 1, batch: 32, loss: 1.8603216409683228\n",
      "Epoch: 1, batch: 48, loss: 1.067273736000061\n",
      "Epoch: 1, batch: 64, loss: 0.7019075751304626\n",
      "Epoch: 1, batch: 80, loss: 0.7316166758537292\n",
      "Epoch: 1, batch: 96, loss: 0.6628550887107849\n",
      "Epoch: 1, batch: 112, loss: 0.8085906505584717\n",
      "Epoch: 1, batch: 128, loss: 0.8517827391624451\n",
      "Epoch: 1, batch: 144, loss: 0.9902262091636658\n",
      "Epoch: 2, batch: 0, loss: 0.9680604934692383\n",
      "Epoch: 2, batch: 16, loss: 0.9518070816993713\n",
      "Epoch: 2, batch: 32, loss: 0.5681368708610535\n",
      "Epoch: 2, batch: 48, loss: 0.589414656162262\n",
      "Epoch: 2, batch: 64, loss: 0.7523965835571289\n",
      "Epoch: 2, batch: 80, loss: 0.6501078009605408\n",
      "Epoch: 2, batch: 96, loss: 0.5189719796180725\n",
      "Epoch: 2, batch: 112, loss: 0.6460301280021667\n",
      "Epoch: 2, batch: 128, loss: 0.7200736403465271\n",
      "Epoch: 2, batch: 144, loss: 0.38261979818344116\n",
      "Epoch: 3, batch: 0, loss: 0.7883133888244629\n",
      "Epoch: 3, batch: 16, loss: 0.8057227730751038\n",
      "Epoch: 3, batch: 32, loss: 0.7914073467254639\n",
      "Epoch: 3, batch: 48, loss: 0.9473715424537659\n",
      "Epoch: 3, batch: 64, loss: 0.9103657603263855\n",
      "Epoch: 3, batch: 80, loss: 0.8204283118247986\n",
      "Epoch: 3, batch: 96, loss: 0.737994909286499\n",
      "Epoch: 3, batch: 112, loss: 0.9283628463745117\n",
      "Epoch: 3, batch: 128, loss: 0.6908804774284363\n",
      "Epoch: 3, batch: 144, loss: 0.6266570687294006\n",
      "Epoch: 4, batch: 0, loss: 0.8809263110160828\n",
      "Epoch: 4, batch: 16, loss: 0.5946463942527771\n",
      "Epoch: 4, batch: 32, loss: 0.9125449061393738\n",
      "Epoch: 4, batch: 48, loss: 0.5584211945533752\n",
      "Epoch: 4, batch: 64, loss: 0.5570316910743713\n",
      "Epoch: 4, batch: 80, loss: 0.42741087079048157\n",
      "Epoch: 4, batch: 96, loss: 0.38252416253089905\n",
      "Epoch: 4, batch: 112, loss: 0.3971366882324219\n",
      "Epoch: 4, batch: 128, loss: 0.45658794045448303\n",
      "Epoch: 4, batch: 144, loss: 0.2359050065279007\n",
      "Epoch: 5, batch: 0, loss: 0.5501202940940857\n",
      "Epoch: 5, batch: 16, loss: 0.3627888858318329\n",
      "Epoch: 5, batch: 32, loss: 0.5058042407035828\n",
      "Epoch: 5, batch: 48, loss: 0.6024488210678101\n",
      "Epoch: 5, batch: 64, loss: 0.830752432346344\n",
      "Epoch: 5, batch: 80, loss: 0.5270171761512756\n",
      "Epoch: 5, batch: 96, loss: 0.5606089234352112\n",
      "Epoch: 5, batch: 112, loss: 0.5700911283493042\n",
      "Epoch: 5, batch: 128, loss: 0.6187213659286499\n",
      "Epoch: 5, batch: 144, loss: 0.7273292541503906\n",
      "Epoch: 6, batch: 0, loss: 0.563843309879303\n",
      "Epoch: 6, batch: 16, loss: 0.6326647996902466\n",
      "Epoch: 6, batch: 32, loss: 0.5470151305198669\n",
      "Epoch: 6, batch: 48, loss: 0.5059500336647034\n",
      "Epoch: 6, batch: 64, loss: 0.8729022145271301\n",
      "Epoch: 6, batch: 80, loss: 0.515925943851471\n",
      "Epoch: 6, batch: 96, loss: 0.46002569794654846\n",
      "Epoch: 6, batch: 112, loss: 0.4577215909957886\n",
      "Epoch: 6, batch: 128, loss: 0.3559197187423706\n",
      "Epoch: 6, batch: 144, loss: 0.3159138262271881\n",
      "Epoch: 7, batch: 0, loss: 0.5437272191047668\n",
      "Epoch: 7, batch: 16, loss: 0.6850258708000183\n",
      "Epoch: 7, batch: 32, loss: 0.4186263382434845\n",
      "Epoch: 7, batch: 48, loss: 0.4716109037399292\n",
      "Epoch: 7, batch: 64, loss: 0.3488903045654297\n",
      "Epoch: 7, batch: 80, loss: 0.5109924674034119\n",
      "Epoch: 7, batch: 96, loss: 0.716818630695343\n",
      "Epoch: 7, batch: 112, loss: 0.656785786151886\n",
      "Epoch: 7, batch: 128, loss: 0.5832827091217041\n",
      "Epoch: 7, batch: 144, loss: 0.3041720986366272\n",
      "Epoch: 8, batch: 0, loss: 0.3621211349964142\n",
      "Epoch: 8, batch: 16, loss: 0.3746449053287506\n",
      "Epoch: 8, batch: 32, loss: 0.41774070262908936\n",
      "Epoch: 8, batch: 48, loss: 0.2820970118045807\n",
      "Epoch: 8, batch: 64, loss: 0.26835936307907104\n",
      "Epoch: 8, batch: 80, loss: 0.20869140326976776\n",
      "Epoch: 8, batch: 96, loss: 0.43323397636413574\n",
      "Epoch: 8, batch: 112, loss: 0.36423444747924805\n",
      "Epoch: 8, batch: 128, loss: 0.34358999133110046\n",
      "Epoch: 8, batch: 144, loss: 0.22449755668640137\n",
      "Epoch: 9, batch: 0, loss: 0.34285154938697815\n",
      "Epoch: 9, batch: 16, loss: 0.28971436619758606\n",
      "Epoch: 9, batch: 32, loss: 0.35118111968040466\n",
      "Epoch: 9, batch: 48, loss: 0.37546512484550476\n",
      "Epoch: 9, batch: 64, loss: 0.24535398185253143\n",
      "Epoch: 9, batch: 80, loss: 0.30935612320899963\n",
      "Epoch: 9, batch: 96, loss: 0.38727548718452454\n",
      "Epoch: 9, batch: 112, loss: 0.4160543978214264\n",
      "Epoch: 9, batch: 128, loss: 0.2528751790523529\n",
      "Epoch: 9, batch: 144, loss: 0.1297737956047058\n",
      "Epoch: 10, batch: 0, loss: 0.2595076858997345\n",
      "Epoch: 10, batch: 16, loss: 0.2283257246017456\n",
      "Epoch: 10, batch: 32, loss: 0.27429479360580444\n",
      "Epoch: 10, batch: 48, loss: 0.2554716169834137\n",
      "Epoch: 10, batch: 64, loss: 0.32847607135772705\n",
      "Epoch: 10, batch: 80, loss: 0.2062276005744934\n",
      "Epoch: 10, batch: 96, loss: 0.20925188064575195\n",
      "Epoch: 10, batch: 112, loss: 0.20383481681346893\n",
      "Epoch: 10, batch: 128, loss: 0.18971548974514008\n",
      "Epoch: 10, batch: 144, loss: 0.23988103866577148\n",
      "Epoch: 11, batch: 0, loss: 0.356906533241272\n",
      "Epoch: 11, batch: 16, loss: 0.2123752236366272\n",
      "Epoch: 11, batch: 32, loss: 0.23021860420703888\n",
      "Epoch: 11, batch: 48, loss: 0.1472725123167038\n",
      "Epoch: 11, batch: 64, loss: 0.2564180791378021\n",
      "Epoch: 11, batch: 80, loss: 0.11676552891731262\n",
      "Epoch: 11, batch: 96, loss: 0.10977811366319656\n",
      "Epoch: 11, batch: 112, loss: 0.06260330229997635\n",
      "Epoch: 11, batch: 128, loss: 0.02504599839448929\n",
      "Epoch: 11, batch: 144, loss: 0.06030254811048508\n",
      "Epoch: 12, batch: 0, loss: 0.19769243896007538\n",
      "Epoch: 12, batch: 16, loss: 0.0809212177991867\n",
      "Epoch: 12, batch: 32, loss: 0.12376827746629715\n",
      "Epoch: 12, batch: 48, loss: 0.1086602434515953\n",
      "Epoch: 12, batch: 64, loss: 0.18188734352588654\n",
      "Epoch: 12, batch: 80, loss: 0.05821289122104645\n",
      "Epoch: 12, batch: 96, loss: 0.15693354606628418\n",
      "Epoch: 12, batch: 112, loss: 0.16127252578735352\n",
      "Epoch: 12, batch: 128, loss: 0.0948023796081543\n",
      "Epoch: 12, batch: 144, loss: 0.13582128286361694\n",
      "Epoch: 13, batch: 0, loss: 0.17257268726825714\n",
      "Epoch: 13, batch: 16, loss: 0.19984756410121918\n",
      "Epoch: 13, batch: 32, loss: 0.12744732201099396\n",
      "Epoch: 13, batch: 48, loss: 0.16290827095508575\n",
      "Epoch: 13, batch: 64, loss: 0.21505671739578247\n",
      "Epoch: 13, batch: 80, loss: 0.1286744326353073\n",
      "Epoch: 13, batch: 96, loss: 0.22323542833328247\n",
      "Epoch: 13, batch: 112, loss: 0.1832665652036667\n",
      "Epoch: 13, batch: 128, loss: 0.06714019924402237\n",
      "Epoch: 13, batch: 144, loss: 0.04100542515516281\n",
      "Epoch: 14, batch: 0, loss: 0.1660594791173935\n",
      "Epoch: 14, batch: 16, loss: 0.13925449550151825\n",
      "Epoch: 14, batch: 32, loss: 0.18183137476444244\n",
      "Epoch: 14, batch: 48, loss: 0.0837530866265297\n",
      "Epoch: 14, batch: 64, loss: 0.12633977830410004\n",
      "Epoch: 14, batch: 80, loss: 0.05972113087773323\n",
      "Epoch: 14, batch: 96, loss: 0.1397051066160202\n",
      "Epoch: 14, batch: 112, loss: 0.12697507441043854\n",
      "Epoch: 14, batch: 128, loss: 0.10512927174568176\n",
      "Epoch: 14, batch: 144, loss: 0.08064498007297516\n",
      "Epoch: 15, batch: 0, loss: 0.29848340153694153\n",
      "Epoch: 15, batch: 16, loss: 0.12712328135967255\n",
      "Epoch: 15, batch: 32, loss: 0.11102993041276932\n",
      "Epoch: 15, batch: 48, loss: 0.09670259803533554\n",
      "Epoch: 15, batch: 64, loss: 0.13233408331871033\n",
      "Epoch: 15, batch: 80, loss: 0.13118185102939606\n",
      "Epoch: 15, batch: 96, loss: 0.15455511212348938\n",
      "Epoch: 15, batch: 112, loss: 0.17784945666790009\n",
      "Epoch: 15, batch: 128, loss: 0.12180491536855698\n",
      "Epoch: 15, batch: 144, loss: 0.08677629381418228\n",
      "Epoch: 16, batch: 0, loss: 0.16709394752979279\n",
      "Epoch: 16, batch: 16, loss: 0.08237571269273758\n",
      "Epoch: 16, batch: 32, loss: 0.06895988434553146\n",
      "Epoch: 16, batch: 48, loss: 0.06606375426054001\n",
      "Epoch: 16, batch: 64, loss: 0.09347421675920486\n",
      "Epoch: 16, batch: 80, loss: 0.060140565037727356\n",
      "Epoch: 16, batch: 96, loss: 0.10270927101373672\n",
      "Epoch: 16, batch: 112, loss: 0.11755964905023575\n",
      "Epoch: 16, batch: 128, loss: 0.11572152376174927\n",
      "Epoch: 16, batch: 144, loss: 0.1312052607536316\n",
      "Epoch: 17, batch: 0, loss: 0.38244691491127014\n",
      "Epoch: 17, batch: 16, loss: 0.15908318758010864\n",
      "Epoch: 17, batch: 32, loss: 0.15689395368099213\n",
      "Epoch: 17, batch: 48, loss: 0.06367768347263336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, batch: 64, loss: 0.08952922374010086\n",
      "Epoch: 17, batch: 80, loss: 0.06975875049829483\n",
      "Epoch: 17, batch: 96, loss: 0.173789843916893\n",
      "Epoch: 17, batch: 112, loss: 0.16950251162052155\n",
      "Epoch: 17, batch: 128, loss: 0.10189759731292725\n",
      "Epoch: 17, batch: 144, loss: 0.15220047533512115\n",
      "Epoch: 18, batch: 0, loss: 0.30893346667289734\n",
      "Epoch: 18, batch: 16, loss: 0.191214919090271\n",
      "Epoch: 18, batch: 32, loss: 0.13576357066631317\n",
      "Epoch: 18, batch: 48, loss: 0.16105471551418304\n",
      "Epoch: 18, batch: 64, loss: 0.1226775273680687\n",
      "Epoch: 18, batch: 80, loss: 0.06565332412719727\n",
      "Epoch: 18, batch: 96, loss: 0.11864554136991501\n",
      "Epoch: 18, batch: 112, loss: 0.12543974816799164\n",
      "Epoch: 18, batch: 128, loss: 0.19139541685581207\n",
      "Epoch: 18, batch: 144, loss: 0.1215011402964592\n",
      "Epoch: 19, batch: 0, loss: 0.24104177951812744\n",
      "Epoch: 19, batch: 16, loss: 0.17305274307727814\n",
      "Epoch: 19, batch: 32, loss: 0.11576201766729355\n",
      "Epoch: 19, batch: 48, loss: 0.16019479930400848\n",
      "Epoch: 19, batch: 64, loss: 0.18198375403881073\n",
      "Epoch: 19, batch: 80, loss: 0.1658339947462082\n",
      "Epoch: 19, batch: 96, loss: 0.2112218737602234\n",
      "Epoch: 19, batch: 112, loss: 0.23057354986667633\n",
      "Epoch: 19, batch: 128, loss: 0.1445700079202652\n",
      "Epoch: 19, batch: 144, loss: 0.11875438690185547\n",
      "Epoch: 20, batch: 0, loss: 0.1595177799463272\n",
      "Epoch: 20, batch: 16, loss: 0.14422614872455597\n",
      "Epoch: 20, batch: 32, loss: 0.13696114718914032\n",
      "Epoch: 20, batch: 48, loss: 0.1728522926568985\n",
      "Epoch: 20, batch: 64, loss: 0.16612644493579865\n",
      "Epoch: 20, batch: 80, loss: 0.1018248125910759\n",
      "Epoch: 20, batch: 96, loss: 0.23516398668289185\n",
      "Epoch: 20, batch: 112, loss: 0.13694702088832855\n",
      "Epoch: 20, batch: 128, loss: 0.07402684539556503\n",
      "Epoch: 20, batch: 144, loss: 0.09885651618242264\n",
      "Epoch: 21, batch: 0, loss: 0.13192929327487946\n",
      "Epoch: 21, batch: 16, loss: 0.1044689491391182\n",
      "Epoch: 21, batch: 32, loss: 0.06832636147737503\n",
      "Epoch: 21, batch: 48, loss: 0.0915508046746254\n",
      "Epoch: 21, batch: 64, loss: 0.12717950344085693\n",
      "Epoch: 21, batch: 80, loss: 0.03315974771976471\n",
      "Epoch: 21, batch: 96, loss: 0.12369958311319351\n",
      "Epoch: 21, batch: 112, loss: 0.14210198819637299\n",
      "Epoch: 21, batch: 128, loss: 0.023361653089523315\n",
      "Epoch: 21, batch: 144, loss: 0.02197619527578354\n",
      "Epoch: 22, batch: 0, loss: 0.1505287140607834\n",
      "Epoch: 22, batch: 16, loss: 0.11643946915864944\n",
      "Epoch: 22, batch: 32, loss: 0.09307055920362473\n",
      "Epoch: 22, batch: 48, loss: 0.12489544600248337\n",
      "Epoch: 22, batch: 64, loss: 0.13643747568130493\n",
      "Epoch: 22, batch: 80, loss: 0.0729769915342331\n",
      "Epoch: 22, batch: 96, loss: 0.14033754169940948\n",
      "Epoch: 22, batch: 112, loss: 0.15589815378189087\n",
      "Epoch: 22, batch: 128, loss: 0.048310890793800354\n",
      "Epoch: 22, batch: 144, loss: 0.04850686341524124\n",
      "Epoch: 23, batch: 0, loss: 0.1499917209148407\n",
      "Epoch: 23, batch: 16, loss: 0.18220208585262299\n",
      "Epoch: 23, batch: 32, loss: 0.14542090892791748\n",
      "Epoch: 23, batch: 48, loss: 0.08799219131469727\n",
      "Epoch: 23, batch: 64, loss: 0.12397988885641098\n",
      "Epoch: 23, batch: 80, loss: 0.05659875273704529\n",
      "Epoch: 23, batch: 96, loss: 0.09921091794967651\n",
      "Epoch: 23, batch: 112, loss: 0.14541976153850555\n",
      "Epoch: 23, batch: 128, loss: 0.03721623495221138\n",
      "Epoch: 23, batch: 144, loss: 0.05458696186542511\n",
      "Epoch: 24, batch: 0, loss: 0.14033107459545135\n",
      "Epoch: 24, batch: 16, loss: 0.11999731510877609\n",
      "Epoch: 24, batch: 32, loss: 0.1007814034819603\n",
      "Epoch: 24, batch: 48, loss: 0.0933210551738739\n",
      "Epoch: 24, batch: 64, loss: 0.10179862380027771\n",
      "Epoch: 24, batch: 80, loss: 0.04357466101646423\n",
      "Epoch: 24, batch: 96, loss: 0.07819599658250809\n",
      "Epoch: 24, batch: 112, loss: 0.12799786031246185\n",
      "Epoch: 24, batch: 128, loss: 0.07285060733556747\n",
      "Epoch: 24, batch: 144, loss: 0.03768482431769371\n",
      "Epoch: 25, batch: 0, loss: 0.13100594282150269\n",
      "Epoch: 25, batch: 16, loss: 0.1418963223695755\n",
      "Epoch: 25, batch: 32, loss: 0.0991641953587532\n",
      "Epoch: 25, batch: 48, loss: 0.1455007940530777\n",
      "Epoch: 25, batch: 64, loss: 0.12577949464321136\n",
      "Epoch: 25, batch: 80, loss: 0.0664762333035469\n",
      "Epoch: 25, batch: 96, loss: 0.15531855821609497\n",
      "Epoch: 25, batch: 112, loss: 0.15229792892932892\n",
      "Epoch: 25, batch: 128, loss: 0.10120155662298203\n",
      "Epoch: 25, batch: 144, loss: 0.0670277401804924\n",
      "Epoch: 26, batch: 0, loss: 0.12022635340690613\n",
      "Epoch: 26, batch: 16, loss: 0.14437077939510345\n",
      "Epoch: 26, batch: 32, loss: 0.08432194590568542\n",
      "Epoch: 26, batch: 48, loss: 0.11521724611520767\n",
      "Epoch: 26, batch: 64, loss: 0.130782350897789\n",
      "Epoch: 26, batch: 80, loss: 0.047012779861688614\n",
      "Epoch: 26, batch: 96, loss: 0.14078743755817413\n",
      "Epoch: 26, batch: 112, loss: 0.08012370020151138\n",
      "Epoch: 26, batch: 128, loss: 0.024758880957961082\n",
      "Epoch: 26, batch: 144, loss: 0.02066117152571678\n",
      "Epoch: 27, batch: 0, loss: 0.17423313856124878\n",
      "Epoch: 27, batch: 16, loss: 0.1801607459783554\n",
      "Epoch: 27, batch: 32, loss: 0.13264985382556915\n",
      "Epoch: 27, batch: 48, loss: 0.14269599318504333\n",
      "Epoch: 27, batch: 64, loss: 0.1301833540201187\n",
      "Epoch: 27, batch: 80, loss: 0.027669033035635948\n",
      "Epoch: 27, batch: 96, loss: 0.10106467455625534\n",
      "Epoch: 27, batch: 112, loss: 0.12244697660207748\n",
      "Epoch: 27, batch: 128, loss: 0.016624674201011658\n",
      "Epoch: 27, batch: 144, loss: 0.03290638327598572\n",
      "Epoch: 28, batch: 0, loss: 0.2529553472995758\n",
      "Epoch: 28, batch: 16, loss: 0.1620551347732544\n",
      "Epoch: 28, batch: 32, loss: 0.07756363600492477\n",
      "Epoch: 28, batch: 48, loss: 0.015384409576654434\n",
      "Epoch: 28, batch: 64, loss: 0.041499774903059006\n",
      "Epoch: 28, batch: 80, loss: 0.010909591801464558\n",
      "Epoch: 28, batch: 96, loss: 0.026355259120464325\n",
      "Epoch: 28, batch: 112, loss: 0.07794230431318283\n",
      "Epoch: 28, batch: 128, loss: 0.022011781111359596\n",
      "Epoch: 28, batch: 144, loss: 0.036769650876522064\n",
      "Epoch: 29, batch: 0, loss: 0.13843144476413727\n",
      "Epoch: 29, batch: 16, loss: 0.14266571402549744\n",
      "Epoch: 29, batch: 32, loss: 0.03604402765631676\n",
      "Epoch: 29, batch: 48, loss: 0.06171117722988129\n",
      "Epoch: 29, batch: 64, loss: 0.0651107057929039\n",
      "Epoch: 29, batch: 80, loss: 0.03549571335315704\n",
      "Epoch: 29, batch: 96, loss: 0.03804515302181244\n",
      "Epoch: 29, batch: 112, loss: 0.06440436094999313\n",
      "Epoch: 29, batch: 128, loss: 0.017633745446801186\n",
      "Epoch: 29, batch: 144, loss: 0.002801402471959591\n",
      "Epoch: 30, batch: 0, loss: 0.17565160989761353\n",
      "Epoch: 30, batch: 16, loss: 0.0072574014775455\n",
      "Epoch: 30, batch: 32, loss: 0.012785724364221096\n",
      "Epoch: 30, batch: 48, loss: 0.0014226218918338418\n",
      "Epoch: 30, batch: 64, loss: 0.006858245003968477\n",
      "Epoch: 30, batch: 80, loss: 0.005599595606327057\n",
      "Epoch: 30, batch: 96, loss: 0.007983609102666378\n",
      "Epoch: 30, batch: 112, loss: 0.06065727770328522\n",
      "Epoch: 30, batch: 128, loss: 0.009451363235712051\n",
      "Epoch: 30, batch: 144, loss: 0.0003964095958508551\n",
      "Epoch: 31, batch: 0, loss: 0.2409723997116089\n",
      "Epoch: 31, batch: 16, loss: 0.0002723725629039109\n",
      "Epoch: 31, batch: 32, loss: 0.01155451312661171\n",
      "Epoch: 31, batch: 48, loss: 0.0016645608702674508\n",
      "Epoch: 31, batch: 64, loss: 0.002328506438061595\n",
      "Epoch: 31, batch: 80, loss: 0.0008381793741136789\n",
      "Epoch: 31, batch: 96, loss: 0.020760321989655495\n",
      "Epoch: 31, batch: 112, loss: 0.014195173978805542\n",
      "Epoch: 31, batch: 128, loss: 0.0011678924784064293\n",
      "Epoch: 31, batch: 144, loss: 0.009221155196428299\n",
      "Epoch: 32, batch: 0, loss: 0.13329000771045685\n",
      "Epoch: 32, batch: 16, loss: 0.00970922876149416\n",
      "Epoch: 32, batch: 32, loss: 0.020502248778939247\n",
      "Epoch: 32, batch: 48, loss: 0.1062413677573204\n",
      "Epoch: 32, batch: 64, loss: 0.08044605702161789\n",
      "Epoch: 32, batch: 80, loss: 0.012698342092335224\n",
      "Epoch: 32, batch: 96, loss: 0.03163505718111992\n",
      "Epoch: 32, batch: 112, loss: 0.02133738435804844\n",
      "Epoch: 32, batch: 128, loss: 0.00831859651952982\n",
      "Epoch: 32, batch: 144, loss: 0.022051220759749413\n",
      "Epoch: 33, batch: 0, loss: 0.3300362825393677\n",
      "Epoch: 33, batch: 16, loss: 0.03567621111869812\n",
      "Epoch: 33, batch: 32, loss: 0.006303443107753992\n",
      "Epoch: 33, batch: 48, loss: 0.004082667641341686\n",
      "Epoch: 33, batch: 64, loss: 0.014981567859649658\n",
      "Epoch: 33, batch: 80, loss: 0.016848361119627953\n",
      "Epoch: 33, batch: 96, loss: 0.03449908643960953\n",
      "Epoch: 33, batch: 112, loss: 0.004955558106303215\n",
      "Epoch: 33, batch: 128, loss: 0.0002766998659353703\n",
      "Epoch: 33, batch: 144, loss: 0.0019550540018826723\n",
      "Epoch: 34, batch: 0, loss: 0.30424633622169495\n",
      "Epoch: 34, batch: 16, loss: 0.026186222210526466\n",
      "Epoch: 34, batch: 32, loss: 0.014001251198351383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, batch: 48, loss: 0.010052735917270184\n",
      "Epoch: 34, batch: 64, loss: 0.052993178367614746\n",
      "Epoch: 34, batch: 80, loss: 0.008125697262585163\n",
      "Epoch: 34, batch: 96, loss: 0.002319388324394822\n",
      "Epoch: 34, batch: 112, loss: 0.0023849455174058676\n",
      "Epoch: 34, batch: 128, loss: 0.011403631418943405\n",
      "Epoch: 34, batch: 144, loss: 3.057676076423377e-05\n",
      "Epoch: 35, batch: 0, loss: 0.024468936026096344\n",
      "Epoch: 35, batch: 16, loss: 0.002460331888869405\n",
      "Epoch: 35, batch: 32, loss: 0.012793944217264652\n",
      "Epoch: 35, batch: 48, loss: 0.007635436952114105\n",
      "Epoch: 35, batch: 64, loss: 0.0373929925262928\n",
      "Epoch: 35, batch: 80, loss: 0.0009613309521228075\n",
      "Epoch: 35, batch: 96, loss: 0.006324369926005602\n",
      "Epoch: 35, batch: 112, loss: 0.01243677455931902\n",
      "Epoch: 35, batch: 128, loss: 0.003803860628977418\n",
      "Epoch: 35, batch: 144, loss: 0.01966117136180401\n",
      "Epoch: 36, batch: 0, loss: 0.38057318329811096\n",
      "Epoch: 36, batch: 16, loss: 0.000455474597401917\n",
      "Epoch: 36, batch: 32, loss: 0.006764108780771494\n",
      "Epoch: 36, batch: 48, loss: 0.08026634156703949\n",
      "Epoch: 36, batch: 64, loss: 0.06796196103096008\n",
      "Epoch: 36, batch: 80, loss: 0.009762895293533802\n",
      "Epoch: 36, batch: 96, loss: 0.07485012710094452\n",
      "Epoch: 36, batch: 112, loss: 0.04006551578640938\n",
      "Epoch: 36, batch: 128, loss: 0.025627465918660164\n",
      "Epoch: 36, batch: 144, loss: 0.00011426743003539741\n",
      "Epoch: 37, batch: 0, loss: 0.1282208412885666\n",
      "Epoch: 37, batch: 16, loss: 0.04659710451960564\n",
      "Epoch: 37, batch: 32, loss: 0.012283666990697384\n",
      "Epoch: 37, batch: 48, loss: 0.08122596889734268\n",
      "Epoch: 37, batch: 64, loss: 0.07145870476961136\n",
      "Epoch: 37, batch: 80, loss: 2.121304532920476e-05\n",
      "Epoch: 37, batch: 96, loss: 0.17862094938755035\n",
      "Epoch: 37, batch: 112, loss: 0.07194206863641739\n",
      "Epoch: 37, batch: 128, loss: 0.09768744558095932\n",
      "Epoch: 37, batch: 144, loss: 0.0048935734666883945\n",
      "Epoch: 38, batch: 0, loss: 0.16113099455833435\n",
      "Epoch: 38, batch: 16, loss: 0.006626076530665159\n",
      "Epoch: 38, batch: 32, loss: 0.05301142856478691\n",
      "Epoch: 38, batch: 48, loss: 0.035877473652362823\n",
      "Epoch: 38, batch: 64, loss: 0.010227537713944912\n",
      "Epoch: 38, batch: 80, loss: 0.004597855266183615\n",
      "Epoch: 38, batch: 96, loss: 0.13457737863063812\n",
      "Epoch: 38, batch: 112, loss: 0.059475358575582504\n",
      "Epoch: 38, batch: 128, loss: 0.09127700328826904\n",
      "Epoch: 38, batch: 144, loss: 0.002128052292391658\n",
      "Epoch: 39, batch: 0, loss: 0.07661926001310349\n",
      "Epoch: 39, batch: 16, loss: 0.023722777143120766\n",
      "Epoch: 39, batch: 32, loss: 0.005903204437345266\n",
      "Epoch: 39, batch: 48, loss: 0.053409457206726074\n",
      "Epoch: 39, batch: 64, loss: 0.07292560487985611\n",
      "Epoch: 39, batch: 80, loss: 0.00048461658298037946\n",
      "Epoch: 39, batch: 96, loss: 0.008450038731098175\n",
      "Epoch: 39, batch: 112, loss: 0.020548207685351372\n",
      "Epoch: 39, batch: 128, loss: 0.008124166168272495\n",
      "Epoch: 39, batch: 144, loss: 0.0004441156634129584\n",
      "Epoch: 40, batch: 0, loss: 0.33145013451576233\n",
      "Epoch: 40, batch: 16, loss: 0.012691873125731945\n",
      "Epoch: 40, batch: 32, loss: 0.0021916234400123358\n",
      "Epoch: 40, batch: 48, loss: 0.005822370294481516\n",
      "Epoch: 40, batch: 64, loss: 0.015873553231358528\n",
      "Epoch: 40, batch: 80, loss: 0.012116403318941593\n",
      "Epoch: 40, batch: 96, loss: 0.01075031328946352\n",
      "Epoch: 40, batch: 112, loss: 0.014973551034927368\n",
      "Epoch: 40, batch: 128, loss: 0.013227148912847042\n",
      "Epoch: 40, batch: 144, loss: 0.0037500602193176746\n",
      "Epoch: 41, batch: 0, loss: 0.3463229835033417\n",
      "Epoch: 41, batch: 16, loss: 0.00037230117595754564\n",
      "Epoch: 41, batch: 32, loss: 0.005937595386058092\n",
      "Epoch: 41, batch: 48, loss: 0.002602500142529607\n",
      "Epoch: 41, batch: 64, loss: 0.010474405251443386\n",
      "Epoch: 41, batch: 80, loss: 0.0016236348310485482\n",
      "Epoch: 41, batch: 96, loss: 0.006116451695561409\n",
      "Epoch: 41, batch: 112, loss: 0.011422754265367985\n",
      "Epoch: 41, batch: 128, loss: 0.00763956131413579\n",
      "Epoch: 41, batch: 144, loss: 0.00011856604396598414\n",
      "Epoch: 42, batch: 0, loss: 0.0681358128786087\n",
      "Epoch: 42, batch: 16, loss: 0.00806945189833641\n",
      "Epoch: 42, batch: 32, loss: 0.022443803027272224\n",
      "Epoch: 42, batch: 48, loss: 0.023384181782603264\n",
      "Epoch: 42, batch: 64, loss: 0.06818140298128128\n",
      "Epoch: 42, batch: 80, loss: 0.0001250727946171537\n",
      "Epoch: 42, batch: 96, loss: 0.039376452565193176\n",
      "Epoch: 42, batch: 112, loss: 0.03229143097996712\n",
      "Epoch: 42, batch: 128, loss: 0.023890718817710876\n",
      "Epoch: 42, batch: 144, loss: 0.0011255983263254166\n",
      "Epoch: 43, batch: 0, loss: 0.0548059307038784\n",
      "Epoch: 43, batch: 16, loss: 0.0004736334958579391\n",
      "Epoch: 43, batch: 32, loss: 0.003228286048397422\n",
      "Epoch: 43, batch: 48, loss: 0.0062263780273497105\n",
      "Epoch: 43, batch: 64, loss: 0.09477991610765457\n",
      "Epoch: 43, batch: 80, loss: 0.01688666082918644\n",
      "Epoch: 43, batch: 96, loss: 0.1427561193704605\n",
      "Epoch: 43, batch: 112, loss: 0.049142494797706604\n",
      "Epoch: 43, batch: 128, loss: 0.05360439792275429\n",
      "Epoch: 43, batch: 144, loss: 0.0015790764009580016\n",
      "Epoch: 44, batch: 0, loss: 0.08193924278020859\n",
      "Epoch: 44, batch: 16, loss: 0.011799032799899578\n",
      "Epoch: 44, batch: 32, loss: 0.0037391297519207\n",
      "Epoch: 44, batch: 48, loss: 0.01427365466952324\n",
      "Epoch: 44, batch: 64, loss: 0.23418866097927094\n",
      "Epoch: 44, batch: 80, loss: 0.0014077649684622884\n",
      "Epoch: 44, batch: 96, loss: 0.04408256709575653\n",
      "Epoch: 44, batch: 112, loss: 0.01933916099369526\n",
      "Epoch: 44, batch: 128, loss: 0.04485927149653435\n",
      "Epoch: 44, batch: 144, loss: 0.010593836195766926\n",
      "Epoch: 45, batch: 0, loss: 0.05153396725654602\n",
      "Epoch: 45, batch: 16, loss: 0.010734590701758862\n",
      "Epoch: 45, batch: 32, loss: 0.01655556447803974\n",
      "Epoch: 45, batch: 48, loss: 0.014500883407890797\n",
      "Epoch: 45, batch: 64, loss: 0.06022826209664345\n",
      "Epoch: 45, batch: 80, loss: 0.0004926628898829222\n",
      "Epoch: 45, batch: 96, loss: 0.026087075471878052\n",
      "Epoch: 45, batch: 112, loss: 0.06439782679080963\n",
      "Epoch: 45, batch: 128, loss: 0.018980735912919044\n",
      "Epoch: 45, batch: 144, loss: 0.0013342902529984713\n",
      "Epoch: 46, batch: 0, loss: 0.11747705936431885\n",
      "Epoch: 46, batch: 16, loss: 0.031034542247653008\n",
      "Epoch: 46, batch: 32, loss: 0.007068914826959372\n",
      "Epoch: 46, batch: 48, loss: 0.013872587122023106\n",
      "Epoch: 46, batch: 64, loss: 0.09189239889383316\n",
      "Epoch: 46, batch: 80, loss: 0.0011411894811317325\n",
      "Epoch: 46, batch: 96, loss: 0.28441423177719116\n",
      "Epoch: 46, batch: 112, loss: 0.07898717373609543\n",
      "Epoch: 46, batch: 128, loss: 0.10711293667554855\n",
      "Epoch: 46, batch: 144, loss: 0.001298463437706232\n",
      "Epoch: 47, batch: 0, loss: 0.1269569844007492\n",
      "Epoch: 47, batch: 16, loss: 0.02869112603366375\n",
      "Epoch: 47, batch: 32, loss: 0.601243257522583\n",
      "Epoch: 47, batch: 48, loss: 0.044910553842782974\n",
      "Epoch: 47, batch: 64, loss: 0.14777207374572754\n",
      "Epoch: 47, batch: 80, loss: 0.00032893483876250684\n",
      "Epoch: 47, batch: 96, loss: 0.13018836081027985\n",
      "Epoch: 47, batch: 112, loss: 0.06209123134613037\n",
      "Epoch: 47, batch: 128, loss: 0.05798184871673584\n",
      "Epoch: 47, batch: 144, loss: 0.002114911563694477\n",
      "Epoch: 48, batch: 0, loss: 0.05661451444029808\n",
      "Epoch: 48, batch: 16, loss: 0.021639583632349968\n",
      "Epoch: 48, batch: 32, loss: 0.00905737653374672\n",
      "Epoch: 48, batch: 48, loss: 0.020950930193066597\n",
      "Epoch: 48, batch: 64, loss: 0.008197453804314137\n",
      "Epoch: 48, batch: 80, loss: 4.3132869905093685e-05\n",
      "Epoch: 48, batch: 96, loss: 0.08780085295438766\n",
      "Epoch: 48, batch: 112, loss: 0.0840444341301918\n",
      "Epoch: 48, batch: 128, loss: 0.03756869211792946\n",
      "Epoch: 48, batch: 144, loss: 0.004808302968740463\n",
      "Epoch: 49, batch: 0, loss: 0.09106037765741348\n",
      "Epoch: 49, batch: 16, loss: 0.0037485857028514147\n",
      "Epoch: 49, batch: 32, loss: 0.030426179990172386\n",
      "Epoch: 49, batch: 48, loss: 0.005482243839651346\n",
      "Epoch: 49, batch: 64, loss: 0.0019206480355933309\n",
      "Epoch: 49, batch: 80, loss: 8.884858107194304e-05\n",
      "Epoch: 49, batch: 96, loss: 0.008859499357640743\n",
      "Epoch: 49, batch: 112, loss: 0.02695549838244915\n",
      "Epoch: 49, batch: 128, loss: 0.016372501850128174\n",
      "Epoch: 49, batch: 144, loss: 0.004388459492474794\n",
      "Epoch: 50, batch: 0, loss: 0.05902361497282982\n",
      "Epoch: 50, batch: 16, loss: 0.03270379826426506\n",
      "Epoch: 50, batch: 32, loss: 0.6024391055107117\n",
      "Epoch: 50, batch: 48, loss: 0.00670778239145875\n",
      "Epoch: 50, batch: 64, loss: 0.06666935235261917\n",
      "Epoch: 50, batch: 80, loss: 0.0003790130140259862\n",
      "Epoch: 50, batch: 96, loss: 0.021341068670153618\n",
      "Epoch: 50, batch: 112, loss: 0.052538175135850906\n",
      "Epoch: 50, batch: 128, loss: 0.011152747087180614\n",
      "Epoch: 50, batch: 144, loss: 0.0015590410912409425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, batch: 0, loss: 0.07374989241361618\n",
      "Epoch: 51, batch: 16, loss: 0.010139510966837406\n",
      "Epoch: 51, batch: 32, loss: 0.002001106273382902\n",
      "Epoch: 51, batch: 48, loss: 0.014534602873027325\n",
      "Epoch: 51, batch: 64, loss: 0.004753883928060532\n",
      "Epoch: 51, batch: 80, loss: 2.468697857693769e-06\n",
      "Epoch: 51, batch: 96, loss: 0.004025258589535952\n",
      "Epoch: 51, batch: 112, loss: 0.01652550883591175\n",
      "Epoch: 51, batch: 128, loss: 0.007541893515735865\n",
      "Epoch: 51, batch: 144, loss: 0.002888481132686138\n",
      "Epoch: 52, batch: 0, loss: 0.0440739206969738\n",
      "Epoch: 52, batch: 16, loss: 0.004005701746791601\n",
      "Epoch: 52, batch: 32, loss: 0.0016438947059214115\n",
      "Epoch: 52, batch: 48, loss: 0.006685614585876465\n",
      "Epoch: 52, batch: 64, loss: 0.0521625317633152\n",
      "Epoch: 52, batch: 80, loss: 7.456103048752993e-05\n",
      "Epoch: 52, batch: 96, loss: 0.0061246235854923725\n",
      "Epoch: 52, batch: 112, loss: 0.006831422448158264\n",
      "Epoch: 52, batch: 128, loss: 0.016910044476389885\n",
      "Epoch: 52, batch: 144, loss: 4.834122955799103e-05\n",
      "Epoch: 53, batch: 0, loss: 0.09462068229913712\n",
      "Epoch: 53, batch: 16, loss: 0.012912540696561337\n",
      "Epoch: 53, batch: 32, loss: 0.29481127858161926\n",
      "Epoch: 53, batch: 48, loss: 0.003395356237888336\n",
      "Epoch: 53, batch: 64, loss: 0.036889512091875076\n",
      "Epoch: 53, batch: 80, loss: 0.008359053172171116\n",
      "Epoch: 53, batch: 96, loss: 0.00944205466657877\n",
      "Epoch: 53, batch: 112, loss: 0.04398025944828987\n",
      "Epoch: 53, batch: 128, loss: 0.02490372024476528\n",
      "Epoch: 53, batch: 144, loss: 0.0016286872560158372\n",
      "Epoch: 54, batch: 0, loss: 0.0477626770734787\n",
      "Epoch: 54, batch: 16, loss: 0.005313029512763023\n",
      "Epoch: 54, batch: 32, loss: 0.0003718874359037727\n",
      "Epoch: 54, batch: 48, loss: 0.0032497721258550882\n",
      "Epoch: 54, batch: 64, loss: 0.04721671715378761\n",
      "Epoch: 54, batch: 80, loss: 0.0005884687998332083\n",
      "Epoch: 54, batch: 96, loss: 0.011235845275223255\n",
      "Epoch: 54, batch: 112, loss: 0.018778113648295403\n",
      "Epoch: 54, batch: 128, loss: 0.011416667141020298\n",
      "Epoch: 54, batch: 144, loss: 0.001220807316713035\n",
      "Epoch: 55, batch: 0, loss: 0.05349845811724663\n",
      "Epoch: 55, batch: 16, loss: 0.008194777183234692\n",
      "Epoch: 55, batch: 32, loss: 0.0008202922181226313\n",
      "Epoch: 55, batch: 48, loss: 0.0043581947684288025\n",
      "Epoch: 55, batch: 64, loss: 0.0833030417561531\n",
      "Epoch: 55, batch: 80, loss: 0.0002490048937033862\n",
      "Epoch: 55, batch: 96, loss: 0.01635979488492012\n",
      "Epoch: 55, batch: 112, loss: 0.0457187183201313\n",
      "Epoch: 55, batch: 128, loss: 0.02303740382194519\n",
      "Epoch: 55, batch: 144, loss: 0.0005492113996297121\n",
      "Epoch: 56, batch: 0, loss: 0.2861576974391937\n",
      "Epoch: 56, batch: 16, loss: 0.0968109741806984\n",
      "Epoch: 56, batch: 32, loss: 0.014089853502810001\n",
      "Epoch: 56, batch: 48, loss: 0.003326733596622944\n",
      "Epoch: 56, batch: 64, loss: 0.12435735017061234\n",
      "Epoch: 56, batch: 80, loss: 0.003981035202741623\n",
      "Epoch: 56, batch: 96, loss: 0.016989707946777344\n",
      "Epoch: 56, batch: 112, loss: 0.026648594066500664\n",
      "Epoch: 56, batch: 128, loss: 0.02894359640777111\n",
      "Epoch: 56, batch: 144, loss: 0.006812745705246925\n",
      "Epoch: 57, batch: 0, loss: 0.08312245458364487\n",
      "Epoch: 57, batch: 16, loss: 0.006678774952888489\n",
      "Epoch: 57, batch: 32, loss: 0.00021374347852542996\n",
      "Epoch: 57, batch: 48, loss: 0.0008818287751637399\n",
      "Epoch: 57, batch: 64, loss: 0.06034572049975395\n",
      "Epoch: 57, batch: 80, loss: 0.0019365317421033978\n",
      "Epoch: 57, batch: 96, loss: 0.012456275522708893\n",
      "Epoch: 57, batch: 112, loss: 0.023636838421225548\n",
      "Epoch: 57, batch: 128, loss: 0.01420548465102911\n",
      "Epoch: 57, batch: 144, loss: 8.609566748418729e-08\n",
      "Epoch: 58, batch: 0, loss: 0.7343493103981018\n",
      "Epoch: 58, batch: 16, loss: 0.0006355222431011498\n",
      "Epoch: 58, batch: 32, loss: 0.0005949781625531614\n",
      "Epoch: 58, batch: 48, loss: 0.0017015129560604692\n",
      "Epoch: 58, batch: 64, loss: 0.03221939876675606\n",
      "Epoch: 58, batch: 80, loss: 8.27080148155801e-05\n",
      "Epoch: 58, batch: 96, loss: 0.01081012561917305\n",
      "Epoch: 58, batch: 112, loss: 0.03423185646533966\n",
      "Epoch: 58, batch: 128, loss: 0.029934532940387726\n",
      "Epoch: 58, batch: 144, loss: 3.6491760511125904e-06\n",
      "Epoch: 59, batch: 0, loss: 0.11036457866430283\n",
      "Epoch: 59, batch: 16, loss: 0.005057896953076124\n",
      "Epoch: 59, batch: 32, loss: 0.0002466257428750396\n",
      "Epoch: 59, batch: 48, loss: 0.009300831705331802\n",
      "Epoch: 59, batch: 64, loss: 0.017373405396938324\n",
      "Epoch: 59, batch: 80, loss: 2.225299340352649e-06\n",
      "Epoch: 59, batch: 96, loss: 0.013240553438663483\n",
      "Epoch: 59, batch: 112, loss: 0.017583584412932396\n",
      "Epoch: 59, batch: 128, loss: 0.005344789009541273\n",
      "Epoch: 59, batch: 144, loss: 0.00010124075197381899\n",
      "Epoch: 60, batch: 0, loss: 0.15201780200004578\n",
      "Epoch: 60, batch: 16, loss: 0.0035403373185545206\n",
      "Epoch: 60, batch: 32, loss: 0.0013187365839257836\n",
      "Epoch: 60, batch: 48, loss: 0.0018133824924007058\n",
      "Epoch: 60, batch: 64, loss: 0.035439807921648026\n",
      "Epoch: 60, batch: 80, loss: 0.000944522675126791\n",
      "Epoch: 60, batch: 96, loss: 0.0019094757735729218\n",
      "Epoch: 60, batch: 112, loss: 0.008442709222435951\n",
      "Epoch: 60, batch: 128, loss: 0.0037459619343280792\n",
      "Epoch: 60, batch: 144, loss: 4.658388934331015e-05\n",
      "Epoch: 61, batch: 0, loss: 0.6024389266967773\n",
      "Epoch: 61, batch: 16, loss: 0.019146861508488655\n",
      "Epoch: 61, batch: 32, loss: 0.006615772843360901\n",
      "Epoch: 61, batch: 48, loss: 2.3915132260299288e-05\n",
      "Epoch: 61, batch: 64, loss: 0.0311599001288414\n",
      "Epoch: 61, batch: 80, loss: 0.0033083397429436445\n",
      "Epoch: 61, batch: 96, loss: 0.009550942108035088\n",
      "Epoch: 61, batch: 112, loss: 0.05907028540968895\n",
      "Epoch: 61, batch: 128, loss: 0.0044401646591722965\n",
      "Epoch: 61, batch: 144, loss: 5.060002422396792e-06\n",
      "Epoch: 62, batch: 0, loss: 0.06364988535642624\n",
      "Epoch: 62, batch: 16, loss: 0.0051937466487288475\n",
      "Epoch: 62, batch: 32, loss: 1.3135296285327058e-05\n",
      "Epoch: 62, batch: 48, loss: 0.004582166206091642\n",
      "Epoch: 62, batch: 64, loss: 0.133280947804451\n",
      "Epoch: 62, batch: 80, loss: 0.00011362786608515307\n",
      "Epoch: 62, batch: 96, loss: 0.00598840182647109\n",
      "Epoch: 62, batch: 112, loss: 0.0919557735323906\n",
      "Epoch: 62, batch: 128, loss: 0.008099365048110485\n",
      "Epoch: 62, batch: 144, loss: 0.003928983584046364\n",
      "Epoch: 63, batch: 0, loss: 0.08811450749635696\n",
      "Epoch: 63, batch: 16, loss: 0.009773061610758305\n",
      "Epoch: 63, batch: 32, loss: 0.0034709135070443153\n",
      "Epoch: 63, batch: 48, loss: 1.0526481673878152e-05\n",
      "Epoch: 63, batch: 64, loss: 0.022961778566241264\n",
      "Epoch: 63, batch: 80, loss: 0.00029649335192516446\n",
      "Epoch: 63, batch: 96, loss: 0.012706279754638672\n",
      "Epoch: 63, batch: 112, loss: 0.009571302682161331\n",
      "Epoch: 63, batch: 128, loss: 0.0014159884303808212\n",
      "Epoch: 63, batch: 144, loss: 1.105113642552169e-05\n",
      "Epoch: 64, batch: 0, loss: 0.1374438852071762\n",
      "Epoch: 64, batch: 16, loss: 0.0011103932047262788\n",
      "Epoch: 64, batch: 32, loss: 0.00024711398873478174\n",
      "Epoch: 64, batch: 48, loss: 0.010501529090106487\n",
      "Epoch: 64, batch: 64, loss: 0.05416411533951759\n",
      "Epoch: 64, batch: 80, loss: 5.227874453339609e-07\n",
      "Epoch: 64, batch: 96, loss: 0.0008121643331833184\n",
      "Epoch: 64, batch: 112, loss: 0.040120240300893784\n",
      "Epoch: 64, batch: 128, loss: 0.0019670070614665747\n",
      "Epoch: 64, batch: 144, loss: 4.867731604463188e-07\n",
      "Epoch: 65, batch: 0, loss: 0.04232702776789665\n",
      "Epoch: 65, batch: 16, loss: 0.005671841558068991\n",
      "Epoch: 65, batch: 32, loss: 0.0008567121694795787\n",
      "Epoch: 65, batch: 48, loss: 2.523412376831402e-06\n",
      "Epoch: 65, batch: 64, loss: 0.09921065717935562\n",
      "Epoch: 65, batch: 80, loss: 3.3354365314153256e-06\n",
      "Epoch: 65, batch: 96, loss: 0.001321757328696549\n",
      "Epoch: 65, batch: 112, loss: 0.03052605129778385\n",
      "Epoch: 65, batch: 128, loss: 0.002438094699755311\n",
      "Epoch: 65, batch: 144, loss: 0.015250946395099163\n",
      "Epoch: 66, batch: 0, loss: 0.014662668108940125\n",
      "Epoch: 66, batch: 16, loss: 0.026785366237163544\n",
      "Epoch: 66, batch: 32, loss: 0.00024334566842298955\n",
      "Epoch: 66, batch: 48, loss: 0.0022987572010606527\n",
      "Epoch: 66, batch: 64, loss: 0.3355090618133545\n",
      "Epoch: 66, batch: 80, loss: 0.0012815886875614524\n",
      "Epoch: 66, batch: 96, loss: 0.005465780850499868\n",
      "Epoch: 66, batch: 112, loss: 0.09251287579536438\n",
      "Epoch: 66, batch: 128, loss: 0.0013724853051826358\n",
      "Epoch: 66, batch: 144, loss: 0.0001664996234467253\n",
      "Epoch: 67, batch: 0, loss: 0.014096924103796482\n",
      "Epoch: 67, batch: 16, loss: 0.014328706078231335\n",
      "Epoch: 67, batch: 32, loss: 3.427281001222582e-07\n",
      "Epoch: 67, batch: 48, loss: 1.6522501027793624e-05\n",
      "Epoch: 67, batch: 64, loss: 0.22262118756771088\n",
      "Epoch: 67, batch: 80, loss: 0.0001613083150004968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, batch: 96, loss: 0.002584283472970128\n",
      "Epoch: 67, batch: 112, loss: 0.04845608398318291\n",
      "Epoch: 67, batch: 128, loss: 0.0008624849724583328\n",
      "Epoch: 67, batch: 144, loss: 2.7087523903901456e-06\n",
      "Epoch: 68, batch: 0, loss: 0.06599237769842148\n",
      "Epoch: 68, batch: 16, loss: 0.019363772124052048\n",
      "Epoch: 68, batch: 32, loss: 0.0005404512048698962\n",
      "Epoch: 68, batch: 48, loss: 0.013627261854708195\n",
      "Epoch: 68, batch: 64, loss: 0.03355328366160393\n",
      "Epoch: 68, batch: 80, loss: 4.052262283948949e-06\n",
      "Epoch: 68, batch: 96, loss: 1.1889062989212107e-05\n",
      "Epoch: 68, batch: 112, loss: 0.006795145105570555\n",
      "Epoch: 68, batch: 128, loss: 0.0006931281532160938\n",
      "Epoch: 68, batch: 144, loss: 0.0044043711386621\n",
      "Epoch: 69, batch: 0, loss: 0.1699928492307663\n",
      "Epoch: 69, batch: 16, loss: 4.704264210886322e-05\n",
      "Epoch: 69, batch: 32, loss: 1.1759831295421463e-06\n",
      "Epoch: 69, batch: 48, loss: 0.005685858894139528\n",
      "Epoch: 69, batch: 64, loss: 0.004574497230350971\n",
      "Epoch: 69, batch: 80, loss: 1.3535264997699414e-07\n",
      "Epoch: 69, batch: 96, loss: 0.00023076198704075068\n",
      "Epoch: 69, batch: 112, loss: 0.03624771907925606\n",
      "Epoch: 69, batch: 128, loss: 0.5829181671142578\n",
      "Epoch: 69, batch: 144, loss: 1.3245478491796803e-08\n",
      "Epoch: 70, batch: 0, loss: 0.6401696801185608\n",
      "Epoch: 70, batch: 16, loss: 0.0002004975831368938\n",
      "Epoch: 70, batch: 32, loss: 0.0012076658895239234\n",
      "Epoch: 70, batch: 48, loss: 3.1238942028721794e-05\n",
      "Epoch: 70, batch: 64, loss: 0.02268628031015396\n",
      "Epoch: 70, batch: 80, loss: 4.820836238650372e-06\n",
      "Epoch: 70, batch: 96, loss: 0.001621738076210022\n",
      "Epoch: 70, batch: 112, loss: 1.1516481637954712\n",
      "Epoch: 70, batch: 128, loss: 0.5756824612617493\n",
      "Epoch: 70, batch: 144, loss: 0.007521390914916992\n",
      "Epoch: 71, batch: 0, loss: 0.7302621006965637\n",
      "Epoch: 71, batch: 16, loss: 0.0006342786946333945\n",
      "Epoch: 71, batch: 32, loss: 0.0014640578301623464\n",
      "Epoch: 71, batch: 48, loss: 0.0005132451769895852\n",
      "Epoch: 71, batch: 64, loss: 7.861508493078873e-05\n",
      "Epoch: 71, batch: 80, loss: 8.750194683670998e-05\n",
      "Epoch: 71, batch: 96, loss: 0.0007595964707434177\n",
      "Epoch: 71, batch: 112, loss: 1.1564627885818481\n",
      "Epoch: 71, batch: 128, loss: 0.013624669052660465\n",
      "Epoch: 71, batch: 144, loss: 9.060644515557215e-06\n",
      "Epoch: 72, batch: 0, loss: 0.7482941150665283\n",
      "Epoch: 72, batch: 16, loss: 3.569027467165142e-05\n",
      "Epoch: 72, batch: 32, loss: 0.00010557604400673881\n",
      "Epoch: 72, batch: 48, loss: 5.2154131680026694e-08\n",
      "Epoch: 72, batch: 64, loss: 0.00470923213288188\n",
      "Epoch: 72, batch: 80, loss: 6.705528221573331e-08\n",
      "Epoch: 72, batch: 96, loss: 0.0001761657913448289\n",
      "Epoch: 72, batch: 112, loss: 0.02307514287531376\n",
      "Epoch: 72, batch: 128, loss: 0.0008032859768718481\n",
      "Epoch: 72, batch: 144, loss: 0.00782900582998991\n",
      "Epoch: 73, batch: 0, loss: 1.1733897924423218\n",
      "Epoch: 73, batch: 16, loss: 0.0001388608943670988\n",
      "Epoch: 73, batch: 32, loss: 0.0020270070526748896\n",
      "Epoch: 73, batch: 48, loss: 2.4090351757877215e-07\n",
      "Epoch: 73, batch: 64, loss: 0.053201910108327866\n",
      "Epoch: 73, batch: 80, loss: 0.0004044082306791097\n",
      "Epoch: 73, batch: 96, loss: 0.00018546175851952285\n",
      "Epoch: 73, batch: 112, loss: 0.008601980283856392\n",
      "Epoch: 73, batch: 128, loss: 0.0016549084102734923\n",
      "Epoch: 73, batch: 144, loss: 1.2428678019205108e-05\n",
      "Epoch: 74, batch: 0, loss: 0.06217409297823906\n",
      "Epoch: 74, batch: 16, loss: 2.8659647796303034e-05\n",
      "Epoch: 74, batch: 32, loss: 0.006108882371336222\n",
      "Epoch: 74, batch: 48, loss: 0.00015184322546701878\n",
      "Epoch: 74, batch: 64, loss: 0.005265656393021345\n",
      "Epoch: 74, batch: 80, loss: 1.2417634698280722e-09\n",
      "Epoch: 74, batch: 96, loss: 0.00015821341366972774\n",
      "Epoch: 74, batch: 112, loss: 0.0015084529295563698\n",
      "Epoch: 74, batch: 128, loss: 0.00019701530982274562\n",
      "Epoch: 74, batch: 144, loss: 0.0031874333508312702\n",
      "Epoch: 75, batch: 0, loss: 0.1662454754114151\n",
      "Epoch: 75, batch: 16, loss: 0.002308945171535015\n",
      "Epoch: 75, batch: 32, loss: 7.078063646304145e-08\n",
      "Epoch: 75, batch: 48, loss: 0.0001652180653763935\n",
      "Epoch: 75, batch: 64, loss: 0.15590915083885193\n",
      "Epoch: 75, batch: 80, loss: 0.0002517748798709363\n",
      "Epoch: 75, batch: 96, loss: 0.5765992403030396\n",
      "Epoch: 75, batch: 112, loss: 0.47158339619636536\n",
      "Epoch: 75, batch: 128, loss: 0.00238463724963367\n",
      "Epoch: 75, batch: 144, loss: 0.00010588252189336345\n",
      "Epoch: 76, batch: 0, loss: 0.5802175402641296\n",
      "Epoch: 76, batch: 16, loss: 0.00013590671005658805\n",
      "Epoch: 76, batch: 32, loss: 0.003939735237509012\n",
      "Epoch: 76, batch: 48, loss: 0.0005093255313113332\n",
      "Epoch: 76, batch: 64, loss: 0.4057166278362274\n",
      "Epoch: 76, batch: 80, loss: 9.081783355213702e-05\n",
      "Epoch: 76, batch: 96, loss: 0.013692270033061504\n",
      "Epoch: 76, batch: 112, loss: 0.04538419842720032\n",
      "Epoch: 76, batch: 128, loss: 0.0024154966231435537\n",
      "Epoch: 76, batch: 144, loss: 2.4005747036426328e-05\n",
      "Epoch: 77, batch: 0, loss: 0.5907658338546753\n",
      "Epoch: 77, batch: 16, loss: 0.007730020675808191\n",
      "Epoch: 77, batch: 32, loss: 0.0031472693663090467\n",
      "Epoch: 77, batch: 48, loss: 4.1265735490014777e-05\n",
      "Epoch: 77, batch: 64, loss: 1.1995002031326294\n",
      "Epoch: 77, batch: 80, loss: 0.00034491371479816735\n",
      "Epoch: 77, batch: 96, loss: 0.00010843331256182864\n",
      "Epoch: 77, batch: 112, loss: 0.012661728076636791\n",
      "Epoch: 77, batch: 128, loss: 2.734763256739825e-05\n",
      "Epoch: 77, batch: 144, loss: 0.0019846325740218163\n",
      "Epoch: 78, batch: 0, loss: 0.031532641500234604\n",
      "Epoch: 78, batch: 16, loss: 0.004413387272506952\n",
      "Epoch: 78, batch: 32, loss: 2.4835271617007493e-09\n",
      "Epoch: 78, batch: 48, loss: 0.0010796935530379415\n",
      "Epoch: 78, batch: 64, loss: 0.03637342154979706\n",
      "Epoch: 78, batch: 80, loss: 0.012382526881992817\n",
      "Epoch: 78, batch: 96, loss: 7.340633601415902e-05\n",
      "Epoch: 78, batch: 112, loss: 0.0028620350640267134\n",
      "Epoch: 78, batch: 128, loss: 0.010267938487231731\n",
      "Epoch: 78, batch: 144, loss: 6.494312401628122e-05\n",
      "Epoch: 79, batch: 0, loss: 0.17891597747802734\n",
      "Epoch: 79, batch: 16, loss: 0.0007656291127204895\n",
      "Epoch: 79, batch: 32, loss: 4.998697477276437e-06\n",
      "Epoch: 79, batch: 48, loss: 0.0011139354901388288\n",
      "Epoch: 79, batch: 64, loss: 0.017056990414857864\n",
      "Epoch: 79, batch: 80, loss: 0.0025073434226214886\n",
      "Epoch: 79, batch: 96, loss: 0.0005617731367237866\n",
      "Epoch: 79, batch: 112, loss: 0.01077864971011877\n",
      "Epoch: 79, batch: 128, loss: 5.861197678314056e-07\n",
      "Epoch: 79, batch: 144, loss: 0.0014765780651941895\n",
      "Epoch: 80, batch: 0, loss: 0.79404217004776\n",
      "Epoch: 80, batch: 16, loss: 8.607903873780742e-05\n",
      "Epoch: 80, batch: 32, loss: 0.00043750135228037834\n",
      "Epoch: 80, batch: 48, loss: 0.00010914302401943132\n",
      "Epoch: 80, batch: 64, loss: 0.018627231940627098\n",
      "Epoch: 80, batch: 80, loss: 1.4901166522918174e-08\n",
      "Epoch: 80, batch: 96, loss: 2.904580469476059e-06\n",
      "Epoch: 80, batch: 112, loss: 0.00042300039785914123\n",
      "Epoch: 80, batch: 128, loss: 5.2485705964500085e-05\n",
      "Epoch: 80, batch: 144, loss: 0.0009924345649778843\n",
      "Epoch: 81, batch: 0, loss: 0.7078681588172913\n",
      "Epoch: 81, batch: 16, loss: 0.0006863039452582598\n",
      "Epoch: 81, batch: 32, loss: 0.0018161922926083207\n",
      "Epoch: 81, batch: 48, loss: 0.00015651942521799356\n",
      "Epoch: 81, batch: 64, loss: 0.0014332556165754795\n",
      "Epoch: 81, batch: 80, loss: 4.794379128725268e-05\n",
      "Epoch: 81, batch: 96, loss: 0.0022037553135305643\n",
      "Epoch: 81, batch: 112, loss: 8.709796384209767e-05\n",
      "Epoch: 81, batch: 128, loss: 0.0010492688743397593\n",
      "Epoch: 81, batch: 144, loss: 2.344498852835386e-06\n",
      "Epoch: 82, batch: 0, loss: 0.5992821455001831\n",
      "Epoch: 82, batch: 16, loss: 0.0008214442059397697\n",
      "Epoch: 82, batch: 32, loss: 2.360928920097649e-05\n",
      "Epoch: 82, batch: 48, loss: 0.01071218028664589\n",
      "Epoch: 82, batch: 64, loss: 6.781677802791819e-05\n",
      "Epoch: 82, batch: 80, loss: 0.0004654445219784975\n",
      "Epoch: 82, batch: 96, loss: 1.7270640134811401\n",
      "Epoch: 82, batch: 112, loss: 0.0012276144698262215\n",
      "Epoch: 82, batch: 128, loss: 0.0011050936300307512\n",
      "Epoch: 82, batch: 144, loss: 8.27842896455877e-08\n",
      "Epoch: 83, batch: 0, loss: 0.9070472121238708\n",
      "Epoch: 83, batch: 16, loss: 8.002371760085225e-05\n",
      "Epoch: 83, batch: 32, loss: 4.479584458749741e-05\n",
      "Epoch: 83, batch: 48, loss: 0.0008279825560748577\n",
      "Epoch: 83, batch: 64, loss: 0.0007841589394956827\n",
      "Epoch: 83, batch: 80, loss: 0.0010844421340152621\n",
      "Epoch: 83, batch: 96, loss: 1.673038363456726\n",
      "Epoch: 83, batch: 112, loss: 0.09349960088729858\n",
      "Epoch: 83, batch: 128, loss: 0.006449077278375626\n",
      "Epoch: 83, batch: 144, loss: 7.436349551426247e-05\n",
      "Epoch: 84, batch: 0, loss: 0.8253154158592224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84, batch: 16, loss: 7.393774285446852e-05\n",
      "Epoch: 84, batch: 32, loss: 0.0002905646397266537\n",
      "Epoch: 84, batch: 48, loss: 0.001844971557147801\n",
      "Epoch: 84, batch: 64, loss: 0.021623888984322548\n",
      "Epoch: 84, batch: 80, loss: 0.0003875151742249727\n",
      "Epoch: 84, batch: 96, loss: 0.0016388093354180455\n",
      "Epoch: 84, batch: 112, loss: 0.0007673152722418308\n",
      "Epoch: 84, batch: 128, loss: 0.0003892310487572104\n",
      "Epoch: 84, batch: 144, loss: 7.285017034064367e-08\n",
      "Epoch: 85, batch: 0, loss: 0.8546666502952576\n",
      "Epoch: 85, batch: 16, loss: 1.266602538407824e-07\n",
      "Epoch: 85, batch: 32, loss: 0.0006446473998948932\n",
      "Epoch: 85, batch: 48, loss: 0.004210053477436304\n",
      "Epoch: 85, batch: 64, loss: 0.005364192184060812\n",
      "Epoch: 85, batch: 80, loss: 6.854647267573455e-07\n",
      "Epoch: 85, batch: 96, loss: 1.6600126400589943e-05\n",
      "Epoch: 85, batch: 112, loss: 0.0052200015634298325\n",
      "Epoch: 85, batch: 128, loss: 8.465551218250766e-06\n",
      "Epoch: 85, batch: 144, loss: 0.008830131962895393\n",
      "Epoch: 86, batch: 0, loss: 2.7041914463043213\n",
      "Epoch: 86, batch: 16, loss: 4.620741310645826e-05\n",
      "Epoch: 86, batch: 32, loss: 9.481126471655443e-05\n",
      "Epoch: 86, batch: 48, loss: 1.2417634698280722e-09\n",
      "Epoch: 86, batch: 64, loss: 0.0005230749375186861\n",
      "Epoch: 86, batch: 80, loss: 0.0019900111947208643\n",
      "Epoch: 86, batch: 96, loss: 1.3659399833443331e-08\n",
      "Epoch: 86, batch: 112, loss: 0.002300283871591091\n",
      "Epoch: 86, batch: 128, loss: 0.00045416507055051625\n",
      "Epoch: 86, batch: 144, loss: 1.2583217312567285e-07\n",
      "Epoch: 87, batch: 0, loss: 1.6928062438964844\n",
      "Epoch: 87, batch: 16, loss: 0.00010430177644593641\n",
      "Epoch: 87, batch: 32, loss: 8.48670897539705e-05\n",
      "Epoch: 87, batch: 48, loss: 0.0008975875098258257\n",
      "Epoch: 87, batch: 64, loss: 4.271701072866563e-07\n",
      "Epoch: 87, batch: 80, loss: 0.00034982975921593606\n",
      "Epoch: 87, batch: 96, loss: 0.0023407950066030025\n",
      "Epoch: 87, batch: 112, loss: 1.2793482542037964\n",
      "Epoch: 87, batch: 128, loss: 0.00013081857468932867\n",
      "Epoch: 87, batch: 144, loss: 6.755233812327788e-07\n",
      "Epoch: 88, batch: 0, loss: 1.453320860862732\n",
      "Epoch: 88, batch: 16, loss: 0.0001694809179753065\n",
      "Epoch: 88, batch: 32, loss: 0.005565186496824026\n",
      "Epoch: 88, batch: 48, loss: 1.5981015167199075e-05\n",
      "Epoch: 88, batch: 64, loss: 0.0004368602531030774\n",
      "Epoch: 88, batch: 80, loss: 1.7384694572797343e-08\n",
      "Epoch: 88, batch: 96, loss: 0.0012008438352495432\n",
      "Epoch: 88, batch: 112, loss: 0.009340777061879635\n",
      "Epoch: 88, batch: 128, loss: 0.00200571003369987\n",
      "Epoch: 88, batch: 144, loss: 3.914175977115519e-06\n",
      "Epoch: 89, batch: 0, loss: 1.1835790872573853\n",
      "Epoch: 89, batch: 16, loss: 0.005123273003846407\n",
      "Epoch: 89, batch: 32, loss: 0.0022136857733130455\n",
      "Epoch: 89, batch: 48, loss: 0.0002315797028131783\n",
      "Epoch: 89, batch: 64, loss: 0.002248693024739623\n",
      "Epoch: 89, batch: 80, loss: 7.450581485102248e-09\n",
      "Epoch: 89, batch: 96, loss: 1.1548431899655043e-07\n",
      "Epoch: 89, batch: 112, loss: 0.010655228048563004\n",
      "Epoch: 89, batch: 128, loss: 3.320470932521857e-05\n",
      "Epoch: 89, batch: 144, loss: 0.0017819644417613745\n",
      "Epoch: 90, batch: 0, loss: 1.9430269002914429\n",
      "Epoch: 90, batch: 16, loss: 0.015448532998561859\n",
      "Epoch: 90, batch: 32, loss: 8.599693683208898e-05\n",
      "Epoch: 90, batch: 48, loss: 2.980233304583635e-08\n",
      "Epoch: 90, batch: 64, loss: 0.5819411277770996\n",
      "Epoch: 90, batch: 80, loss: 0.0002600157749839127\n",
      "Epoch: 90, batch: 96, loss: 2.170671677959035e-06\n",
      "Epoch: 90, batch: 112, loss: 0.5814278721809387\n",
      "Epoch: 90, batch: 128, loss: 1.7384694572797343e-08\n",
      "Epoch: 90, batch: 144, loss: 2.6490958759950445e-08\n",
      "Epoch: 91, batch: 0, loss: 1.1521075963974\n",
      "Epoch: 91, batch: 16, loss: 3.47694033564494e-08\n",
      "Epoch: 91, batch: 32, loss: 0.0009600539342500269\n",
      "Epoch: 91, batch: 48, loss: 9.934108646802997e-09\n",
      "Epoch: 91, batch: 64, loss: 8.355953468708321e-05\n",
      "Epoch: 91, batch: 80, loss: 2.299872676303494e-06\n",
      "Epoch: 91, batch: 96, loss: 9.933160617947578e-05\n",
      "Epoch: 91, batch: 112, loss: 0.0040978300385177135\n",
      "Epoch: 91, batch: 128, loss: 0.00012256948684807867\n",
      "Epoch: 91, batch: 144, loss: 0.000376374926418066\n",
      "Epoch: 92, batch: 0, loss: 1.585409164428711\n",
      "Epoch: 92, batch: 16, loss: 5.463807042360713e-07\n",
      "Epoch: 92, batch: 32, loss: 0.00026124942814931273\n",
      "Epoch: 92, batch: 48, loss: 2.1471214495250024e-05\n",
      "Epoch: 92, batch: 64, loss: 0.0004993507754988968\n",
      "Epoch: 92, batch: 80, loss: 2.483528227514853e-08\n",
      "Epoch: 92, batch: 96, loss: 7.441397610818967e-05\n",
      "Epoch: 92, batch: 112, loss: 0.03110886923968792\n",
      "Epoch: 92, batch: 128, loss: 2.483528227514853e-08\n",
      "Epoch: 92, batch: 144, loss: 0.00024998714798130095\n",
      "Epoch: 93, batch: 0, loss: 1.2747429609298706\n",
      "Epoch: 93, batch: 16, loss: 3.104409884713277e-08\n",
      "Epoch: 93, batch: 32, loss: 1.1522897481918335\n",
      "Epoch: 93, batch: 48, loss: 7.152152102207765e-05\n",
      "Epoch: 93, batch: 64, loss: 0.1533106416463852\n",
      "Epoch: 93, batch: 80, loss: 1.2169317642474198e-07\n",
      "Epoch: 93, batch: 96, loss: 0.00039883307181298733\n",
      "Epoch: 93, batch: 112, loss: 0.06019733473658562\n",
      "Epoch: 93, batch: 128, loss: 0.00011557153629837558\n",
      "Epoch: 93, batch: 144, loss: 1.3245478491796803e-08\n",
      "Epoch: 94, batch: 0, loss: 0.601867139339447\n",
      "Epoch: 94, batch: 16, loss: 2.401695610387833e-06\n",
      "Epoch: 94, batch: 32, loss: 3.1591807783115655e-06\n",
      "Epoch: 94, batch: 48, loss: 4.9646896513877437e-05\n",
      "Epoch: 94, batch: 64, loss: 0.05619652941823006\n",
      "Epoch: 94, batch: 80, loss: 9.313237114838557e-08\n",
      "Epoch: 94, batch: 96, loss: 0.0003302542900200933\n",
      "Epoch: 94, batch: 112, loss: 0.021678656339645386\n",
      "Epoch: 94, batch: 128, loss: 0.006517644971609116\n",
      "Epoch: 94, batch: 144, loss: 0.003452686360105872\n",
      "Epoch: 95, batch: 0, loss: 0.7741360664367676\n",
      "Epoch: 95, batch: 16, loss: 0.002046150853857398\n",
      "Epoch: 95, batch: 32, loss: 0.0006207157857716084\n",
      "Epoch: 95, batch: 48, loss: 0.0003916573477908969\n",
      "Epoch: 95, batch: 64, loss: 0.036145102232694626\n",
      "Epoch: 95, batch: 80, loss: 0.0031367794144898653\n",
      "Epoch: 95, batch: 96, loss: 0.0023167047183960676\n",
      "Epoch: 95, batch: 112, loss: 0.2561904788017273\n",
      "Epoch: 95, batch: 128, loss: 0.00012487695494201034\n",
      "Epoch: 95, batch: 144, loss: 5.2981931730755605e-08\n",
      "Epoch: 96, batch: 0, loss: 0.6888077855110168\n",
      "Epoch: 96, batch: 16, loss: 0.00040145323146134615\n",
      "Epoch: 96, batch: 32, loss: 5.5535099818371236e-05\n",
      "Epoch: 96, batch: 48, loss: 0.0018692356534302235\n",
      "Epoch: 96, batch: 64, loss: 0.1523769348859787\n",
      "Epoch: 96, batch: 80, loss: 2.933743962785229e-05\n",
      "Epoch: 96, batch: 96, loss: 3.231182745366823e-06\n",
      "Epoch: 96, batch: 112, loss: 0.041433099657297134\n",
      "Epoch: 96, batch: 128, loss: 0.0002581798762548715\n",
      "Epoch: 96, batch: 144, loss: 0.0009812964126467705\n",
      "Epoch: 97, batch: 0, loss: 0.7842119336128235\n",
      "Epoch: 97, batch: 16, loss: 0.009401966817677021\n",
      "Epoch: 97, batch: 32, loss: 2.806396537380351e-07\n",
      "Epoch: 97, batch: 48, loss: 0.0023513082414865494\n",
      "Epoch: 97, batch: 64, loss: 0.08015991002321243\n",
      "Epoch: 97, batch: 80, loss: 4.2219998164227945e-08\n",
      "Epoch: 97, batch: 96, loss: 0.003951280377805233\n",
      "Epoch: 97, batch: 112, loss: 0.019069261848926544\n",
      "Epoch: 97, batch: 128, loss: 0.0028806664049625397\n",
      "Epoch: 97, batch: 144, loss: 4.636110588762676e-06\n",
      "Epoch: 98, batch: 0, loss: 0.5709136724472046\n",
      "Epoch: 98, batch: 16, loss: 0.0009262480307370424\n",
      "Epoch: 98, batch: 32, loss: 3.8732388929929584e-05\n",
      "Epoch: 98, batch: 48, loss: 6.084649584181534e-08\n",
      "Epoch: 98, batch: 64, loss: 0.1207003965973854\n",
      "Epoch: 98, batch: 80, loss: 3.968728196923621e-05\n",
      "Epoch: 98, batch: 96, loss: 7.735323015367612e-05\n",
      "Epoch: 98, batch: 112, loss: 0.0076066479086875916\n",
      "Epoch: 98, batch: 128, loss: 0.00035124181886203587\n",
      "Epoch: 98, batch: 144, loss: 0.0016668393509462476\n",
      "Epoch: 99, batch: 0, loss: 0.7773528099060059\n",
      "Epoch: 99, batch: 16, loss: 0.00015351235924754292\n",
      "Epoch: 99, batch: 32, loss: 0.0008887755684554577\n",
      "Epoch: 99, batch: 48, loss: 1.2417634698280722e-09\n",
      "Epoch: 99, batch: 64, loss: 0.06064639985561371\n",
      "Epoch: 99, batch: 80, loss: 5.339589392860944e-08\n",
      "Epoch: 99, batch: 96, loss: 5.563155696108879e-07\n",
      "Epoch: 99, batch: 112, loss: 0.12450925260782242\n",
      "Epoch: 99, batch: 128, loss: 5.078874210084905e-07\n",
      "Epoch: 99, batch: 144, loss: 2.5398780962859746e-06\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_data.size()[0], batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        \n",
    "        x, y = x_data[indices], y_data[indices]\n",
    "        y_pred=model(x.float())\n",
    "        \n",
    "        def closure():\n",
    "            y_pred = model(x.float())\n",
    "            loss = loss_f(y_pred, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        loss = opt.step(closure)\n",
    "        print (f'Epoch: {str(epoch)}, batch: {str(i)}, loss: {loss}')\n",
    "duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.63637447357178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing time (in seconds) required for training\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now changing the optimizer to Gradient Descent\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch: 0, loss: 0.7108926773071289\n",
      "Epoch: 0, batch: 16, loss: 0.7198290824890137\n",
      "Epoch: 0, batch: 32, loss: 0.6937561631202698\n",
      "Epoch: 0, batch: 48, loss: 0.6946389079093933\n",
      "Epoch: 0, batch: 64, loss: 0.7167690396308899\n",
      "Epoch: 0, batch: 80, loss: 0.6990072131156921\n",
      "Epoch: 0, batch: 96, loss: 0.7288073897361755\n",
      "Epoch: 0, batch: 112, loss: 0.7033264636993408\n",
      "Epoch: 0, batch: 128, loss: 0.6821077466011047\n",
      "Epoch: 0, batch: 144, loss: 0.6250627040863037\n",
      "Epoch: 1, batch: 0, loss: 0.6454740166664124\n",
      "Epoch: 1, batch: 16, loss: 0.6295414566993713\n",
      "Epoch: 1, batch: 32, loss: 0.636696457862854\n",
      "Epoch: 1, batch: 48, loss: 0.622603714466095\n",
      "Epoch: 1, batch: 64, loss: 0.6523577570915222\n",
      "Epoch: 1, batch: 80, loss: 0.6703734397888184\n",
      "Epoch: 1, batch: 96, loss: 0.6608941555023193\n",
      "Epoch: 1, batch: 112, loss: 0.6487292647361755\n",
      "Epoch: 1, batch: 128, loss: 0.6278406977653503\n",
      "Epoch: 1, batch: 144, loss: 0.5510778427124023\n",
      "Epoch: 2, batch: 0, loss: 0.6027626991271973\n",
      "Epoch: 2, batch: 16, loss: 0.5727253556251526\n",
      "Epoch: 2, batch: 32, loss: 0.6085711121559143\n",
      "Epoch: 2, batch: 48, loss: 0.5879462361335754\n",
      "Epoch: 2, batch: 64, loss: 0.6213445067405701\n",
      "Epoch: 2, batch: 80, loss: 0.656330943107605\n",
      "Epoch: 2, batch: 96, loss: 0.631076991558075\n",
      "Epoch: 2, batch: 112, loss: 0.6233965754508972\n",
      "Epoch: 2, batch: 128, loss: 0.6050530076026917\n",
      "Epoch: 2, batch: 144, loss: 0.53355872631073\n",
      "Epoch: 3, batch: 0, loss: 0.5887616276741028\n",
      "Epoch: 3, batch: 16, loss: 0.5591854453086853\n",
      "Epoch: 3, batch: 32, loss: 0.5967180132865906\n",
      "Epoch: 3, batch: 48, loss: 0.576218843460083\n",
      "Epoch: 3, batch: 64, loss: 0.6058627963066101\n",
      "Epoch: 3, batch: 80, loss: 0.6426184773445129\n",
      "Epoch: 3, batch: 96, loss: 0.6124805212020874\n",
      "Epoch: 3, batch: 112, loss: 0.6061988472938538\n",
      "Epoch: 3, batch: 128, loss: 0.5892695784568787\n",
      "Epoch: 3, batch: 144, loss: 0.5241400599479675\n",
      "Epoch: 4, batch: 0, loss: 0.5749688744544983\n",
      "Epoch: 4, batch: 16, loss: 0.5468453168869019\n",
      "Epoch: 4, batch: 32, loss: 0.5791193842887878\n",
      "Epoch: 4, batch: 48, loss: 0.5597025156021118\n",
      "Epoch: 4, batch: 64, loss: 0.5870516896247864\n",
      "Epoch: 4, batch: 80, loss: 0.6165004372596741\n",
      "Epoch: 4, batch: 96, loss: 0.5899618268013\n",
      "Epoch: 4, batch: 112, loss: 0.5832179188728333\n",
      "Epoch: 4, batch: 128, loss: 0.5672383904457092\n",
      "Epoch: 4, batch: 144, loss: 0.5066118836402893\n",
      "Epoch: 5, batch: 0, loss: 0.5510465502738953\n",
      "Epoch: 5, batch: 16, loss: 0.5289240479469299\n",
      "Epoch: 5, batch: 32, loss: 0.5501945614814758\n",
      "Epoch: 5, batch: 48, loss: 0.5346062779426575\n",
      "Epoch: 5, batch: 64, loss: 0.5639022588729858\n",
      "Epoch: 5, batch: 80, loss: 0.5777000188827515\n",
      "Epoch: 5, batch: 96, loss: 0.5664663314819336\n",
      "Epoch: 5, batch: 112, loss: 0.5560179948806763\n",
      "Epoch: 5, batch: 128, loss: 0.5402873158454895\n",
      "Epoch: 5, batch: 144, loss: 0.4841727018356323\n",
      "Epoch: 6, batch: 0, loss: 0.5182098746299744\n",
      "Epoch: 6, batch: 16, loss: 0.5064341425895691\n",
      "Epoch: 6, batch: 32, loss: 0.5090668201446533\n",
      "Epoch: 6, batch: 48, loss: 0.49986305832862854\n",
      "Epoch: 6, batch: 64, loss: 0.5334898233413696\n",
      "Epoch: 6, batch: 80, loss: 0.5287190079689026\n",
      "Epoch: 6, batch: 96, loss: 0.5393791794776917\n",
      "Epoch: 6, batch: 112, loss: 0.5222128033638\n",
      "Epoch: 6, batch: 128, loss: 0.504813015460968\n",
      "Epoch: 6, batch: 144, loss: 0.44669097661972046\n",
      "Epoch: 7, batch: 0, loss: 0.474664568901062\n",
      "Epoch: 7, batch: 16, loss: 0.47149571776390076\n",
      "Epoch: 7, batch: 32, loss: 0.45787057280540466\n",
      "Epoch: 7, batch: 48, loss: 0.4540981948375702\n",
      "Epoch: 7, batch: 64, loss: 0.4955767095088959\n",
      "Epoch: 7, batch: 80, loss: 0.47178876399993896\n",
      "Epoch: 7, batch: 96, loss: 0.5067930817604065\n",
      "Epoch: 7, batch: 112, loss: 0.48199042677879333\n",
      "Epoch: 7, batch: 128, loss: 0.4618227481842041\n",
      "Epoch: 7, batch: 144, loss: 0.40355196595191956\n",
      "Epoch: 8, batch: 0, loss: 0.42365002632141113\n",
      "Epoch: 8, batch: 16, loss: 0.4328407943248749\n",
      "Epoch: 8, batch: 32, loss: 0.39946243166923523\n",
      "Epoch: 8, batch: 48, loss: 0.4045993387699127\n",
      "Epoch: 8, batch: 64, loss: 0.4524558484554291\n",
      "Epoch: 8, batch: 80, loss: 0.4117693603038788\n",
      "Epoch: 8, batch: 96, loss: 0.47142329812049866\n",
      "Epoch: 8, batch: 112, loss: 0.44143757224082947\n",
      "Epoch: 8, batch: 128, loss: 0.41773152351379395\n",
      "Epoch: 8, batch: 144, loss: 0.3587735593318939\n",
      "Epoch: 9, batch: 0, loss: 0.3744429051876068\n",
      "Epoch: 9, batch: 16, loss: 0.3918507993221283\n",
      "Epoch: 9, batch: 32, loss: 0.34736236929893494\n",
      "Epoch: 9, batch: 48, loss: 0.35914549231529236\n",
      "Epoch: 9, batch: 64, loss: 0.41229867935180664\n",
      "Epoch: 9, batch: 80, loss: 0.35938549041748047\n",
      "Epoch: 9, batch: 96, loss: 0.4385264217853546\n",
      "Epoch: 9, batch: 112, loss: 0.40607523918151855\n",
      "Epoch: 9, batch: 128, loss: 0.379713773727417\n",
      "Epoch: 9, batch: 144, loss: 0.3269747793674469\n",
      "Epoch: 10, batch: 0, loss: 0.3349078595638275\n",
      "Epoch: 10, batch: 16, loss: 0.3631582260131836\n",
      "Epoch: 10, batch: 32, loss: 0.30721262097358704\n",
      "Epoch: 10, batch: 48, loss: 0.3264103829860687\n",
      "Epoch: 10, batch: 64, loss: 0.3801431655883789\n",
      "Epoch: 10, batch: 80, loss: 0.32013824582099915\n",
      "Epoch: 10, batch: 96, loss: 0.41195163130760193\n",
      "Epoch: 10, batch: 112, loss: 0.3799777925014496\n",
      "Epoch: 10, batch: 128, loss: 0.35142719745635986\n",
      "Epoch: 10, batch: 144, loss: 0.30709007382392883\n",
      "Epoch: 11, batch: 0, loss: 0.3087451457977295\n",
      "Epoch: 11, batch: 16, loss: 0.3440719544887543\n",
      "Epoch: 11, batch: 32, loss: 0.2810758948326111\n",
      "Epoch: 11, batch: 48, loss: 0.3054952621459961\n",
      "Epoch: 11, batch: 64, loss: 0.35664165019989014\n",
      "Epoch: 11, batch: 80, loss: 0.29153549671173096\n",
      "Epoch: 11, batch: 96, loss: 0.39062556624412537\n",
      "Epoch: 11, batch: 112, loss: 0.36057600378990173\n",
      "Epoch: 11, batch: 128, loss: 0.3314378559589386\n",
      "Epoch: 11, batch: 144, loss: 0.29832860827445984\n",
      "Epoch: 12, batch: 0, loss: 0.29206833243370056\n",
      "Epoch: 12, batch: 16, loss: 0.3335253894329071\n",
      "Epoch: 12, batch: 32, loss: 0.2642475664615631\n",
      "Epoch: 12, batch: 48, loss: 0.29211458563804626\n",
      "Epoch: 12, batch: 64, loss: 0.3399876058101654\n",
      "Epoch: 12, batch: 80, loss: 0.27237269282341003\n",
      "Epoch: 12, batch: 96, loss: 0.3743886649608612\n",
      "Epoch: 12, batch: 112, loss: 0.34638166427612305\n",
      "Epoch: 12, batch: 128, loss: 0.31672313809394836\n",
      "Epoch: 12, batch: 144, loss: 0.2922651469707489\n",
      "Epoch: 13, batch: 0, loss: 0.2812102735042572\n",
      "Epoch: 13, batch: 16, loss: 0.3258855640888214\n",
      "Epoch: 13, batch: 32, loss: 0.2528268098831177\n",
      "Epoch: 13, batch: 48, loss: 0.28217005729675293\n",
      "Epoch: 13, batch: 64, loss: 0.3281337022781372\n",
      "Epoch: 13, batch: 80, loss: 0.26014676690101624\n",
      "Epoch: 13, batch: 96, loss: 0.36247846484184265\n",
      "Epoch: 13, batch: 112, loss: 0.33592164516448975\n",
      "Epoch: 13, batch: 128, loss: 0.3052879273891449\n",
      "Epoch: 13, batch: 144, loss: 0.2856243848800659\n",
      "Epoch: 14, batch: 0, loss: 0.27302268147468567\n",
      "Epoch: 14, batch: 16, loss: 0.3193844258785248\n",
      "Epoch: 14, batch: 32, loss: 0.24400073289871216\n",
      "Epoch: 14, batch: 48, loss: 0.2737254202365875\n",
      "Epoch: 14, batch: 64, loss: 0.3193154036998749\n",
      "Epoch: 14, batch: 80, loss: 0.25231826305389404\n",
      "Epoch: 14, batch: 96, loss: 0.3531550467014313\n",
      "Epoch: 14, batch: 112, loss: 0.32766756415367126\n",
      "Epoch: 14, batch: 128, loss: 0.29568156599998474\n",
      "Epoch: 14, batch: 144, loss: 0.27927181124687195\n",
      "Epoch: 15, batch: 0, loss: 0.26656195521354675\n",
      "Epoch: 15, batch: 16, loss: 0.31369414925575256\n",
      "Epoch: 15, batch: 32, loss: 0.2369414120912552\n",
      "Epoch: 15, batch: 48, loss: 0.2663724422454834\n",
      "Epoch: 15, batch: 64, loss: 0.3120873272418976\n",
      "Epoch: 15, batch: 80, loss: 0.24690139293670654\n",
      "Epoch: 15, batch: 96, loss: 0.34528347849845886\n",
      "Epoch: 15, batch: 112, loss: 0.32087764143943787\n",
      "Epoch: 15, batch: 128, loss: 0.287257581949234\n",
      "Epoch: 15, batch: 144, loss: 0.27268245816230774\n",
      "Epoch: 16, batch: 0, loss: 0.2611456513404846\n",
      "Epoch: 16, batch: 16, loss: 0.3087044060230255\n",
      "Epoch: 16, batch: 32, loss: 0.23094059526920319\n",
      "Epoch: 16, batch: 48, loss: 0.25999781489372253\n",
      "Epoch: 16, batch: 64, loss: 0.30562958121299744\n",
      "Epoch: 16, batch: 80, loss: 0.24227339029312134\n",
      "Epoch: 16, batch: 96, loss: 0.337706595659256\n",
      "Epoch: 16, batch: 112, loss: 0.31478220224380493\n",
      "Epoch: 16, batch: 128, loss: 0.27965983748435974\n",
      "Epoch: 16, batch: 144, loss: 0.2672501802444458\n",
      "Epoch: 17, batch: 0, loss: 0.2565428912639618\n",
      "Epoch: 17, batch: 16, loss: 0.30386438965797424\n",
      "Epoch: 17, batch: 32, loss: 0.22568346560001373\n",
      "Epoch: 17, batch: 48, loss: 0.25388070940971375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, batch: 64, loss: 0.3002234995365143\n",
      "Epoch: 17, batch: 80, loss: 0.2388046532869339\n",
      "Epoch: 17, batch: 96, loss: 0.3312332332134247\n",
      "Epoch: 17, batch: 112, loss: 0.3095703125\n",
      "Epoch: 17, batch: 128, loss: 0.272870808839798\n",
      "Epoch: 17, batch: 144, loss: 0.2619389295578003\n",
      "Epoch: 18, batch: 0, loss: 0.2524125277996063\n",
      "Epoch: 18, batch: 16, loss: 0.29941248893737793\n",
      "Epoch: 18, batch: 32, loss: 0.2209010273218155\n",
      "Epoch: 18, batch: 48, loss: 0.2482268214225769\n",
      "Epoch: 18, batch: 64, loss: 0.29544419050216675\n",
      "Epoch: 18, batch: 80, loss: 0.23576509952545166\n",
      "Epoch: 18, batch: 96, loss: 0.3253612816333771\n",
      "Epoch: 18, batch: 112, loss: 0.3049931228160858\n",
      "Epoch: 18, batch: 128, loss: 0.2666374742984772\n",
      "Epoch: 18, batch: 144, loss: 0.2573660910129547\n",
      "Epoch: 19, batch: 0, loss: 0.24874861538410187\n",
      "Epoch: 19, batch: 16, loss: 0.29550373554229736\n",
      "Epoch: 19, batch: 32, loss: 0.21654053032398224\n",
      "Epoch: 19, batch: 48, loss: 0.24320296943187714\n",
      "Epoch: 19, batch: 64, loss: 0.2907392680644989\n",
      "Epoch: 19, batch: 80, loss: 0.23221909999847412\n",
      "Epoch: 19, batch: 96, loss: 0.3192533254623413\n",
      "Epoch: 19, batch: 112, loss: 0.30060216784477234\n",
      "Epoch: 19, batch: 128, loss: 0.26082509756088257\n",
      "Epoch: 19, batch: 144, loss: 0.2539787292480469\n",
      "Epoch: 20, batch: 0, loss: 0.24538826942443848\n",
      "Epoch: 20, batch: 16, loss: 0.2915779650211334\n",
      "Epoch: 20, batch: 32, loss: 0.2125423699617386\n",
      "Epoch: 20, batch: 48, loss: 0.23827379941940308\n",
      "Epoch: 20, batch: 64, loss: 0.28676873445510864\n",
      "Epoch: 20, batch: 80, loss: 0.2295677214860916\n",
      "Epoch: 20, batch: 96, loss: 0.3145501911640167\n",
      "Epoch: 20, batch: 112, loss: 0.2971878945827484\n",
      "Epoch: 20, batch: 128, loss: 0.2555733025074005\n",
      "Epoch: 20, batch: 144, loss: 0.24932071566581726\n",
      "Epoch: 21, batch: 0, loss: 0.24206633865833282\n",
      "Epoch: 21, batch: 16, loss: 0.2876339852809906\n",
      "Epoch: 21, batch: 32, loss: 0.20853234827518463\n",
      "Epoch: 21, batch: 48, loss: 0.2336321324110031\n",
      "Epoch: 21, batch: 64, loss: 0.28271758556365967\n",
      "Epoch: 21, batch: 80, loss: 0.22611336410045624\n",
      "Epoch: 21, batch: 96, loss: 0.30895641446113586\n",
      "Epoch: 21, batch: 112, loss: 0.29325684905052185\n",
      "Epoch: 21, batch: 128, loss: 0.2503921687602997\n",
      "Epoch: 21, batch: 144, loss: 0.24710038304328918\n",
      "Epoch: 22, batch: 0, loss: 0.23926033079624176\n",
      "Epoch: 22, batch: 16, loss: 0.2841261625289917\n",
      "Epoch: 22, batch: 32, loss: 0.20503705739974976\n",
      "Epoch: 22, batch: 48, loss: 0.22936232388019562\n",
      "Epoch: 22, batch: 64, loss: 0.27909550070762634\n",
      "Epoch: 22, batch: 80, loss: 0.22339247167110443\n",
      "Epoch: 22, batch: 96, loss: 0.3044409453868866\n",
      "Epoch: 22, batch: 112, loss: 0.29020389914512634\n",
      "Epoch: 22, batch: 128, loss: 0.24561326205730438\n",
      "Epoch: 22, batch: 144, loss: 0.24315203726291656\n",
      "Epoch: 23, batch: 0, loss: 0.23624800145626068\n",
      "Epoch: 23, batch: 16, loss: 0.2805490493774414\n",
      "Epoch: 23, batch: 32, loss: 0.20130062103271484\n",
      "Epoch: 23, batch: 48, loss: 0.22494743764400482\n",
      "Epoch: 23, batch: 64, loss: 0.2757432460784912\n",
      "Epoch: 23, batch: 80, loss: 0.22080044448375702\n",
      "Epoch: 23, batch: 96, loss: 0.30005189776420593\n",
      "Epoch: 23, batch: 112, loss: 0.2872215807437897\n",
      "Epoch: 23, batch: 128, loss: 0.24087393283843994\n",
      "Epoch: 23, batch: 144, loss: 0.2396392524242401\n",
      "Epoch: 24, batch: 0, loss: 0.23359781503677368\n",
      "Epoch: 24, batch: 16, loss: 0.27688664197921753\n",
      "Epoch: 24, batch: 32, loss: 0.1977967768907547\n",
      "Epoch: 24, batch: 48, loss: 0.22087234258651733\n",
      "Epoch: 24, batch: 64, loss: 0.27211546897888184\n",
      "Epoch: 24, batch: 80, loss: 0.217438742518425\n",
      "Epoch: 24, batch: 96, loss: 0.29481270909309387\n",
      "Epoch: 24, batch: 112, loss: 0.28360721468925476\n",
      "Epoch: 24, batch: 128, loss: 0.23617565631866455\n",
      "Epoch: 24, batch: 144, loss: 0.23707185685634613\n",
      "Epoch: 25, batch: 0, loss: 0.23101383447647095\n",
      "Epoch: 25, batch: 16, loss: 0.2732919454574585\n",
      "Epoch: 25, batch: 32, loss: 0.19429148733615875\n",
      "Epoch: 25, batch: 48, loss: 0.21667887270450592\n",
      "Epoch: 25, batch: 64, loss: 0.26879170536994934\n",
      "Epoch: 25, batch: 80, loss: 0.21447999775409698\n",
      "Epoch: 25, batch: 96, loss: 0.28997692465782166\n",
      "Epoch: 25, batch: 112, loss: 0.2802647054195404\n",
      "Epoch: 25, batch: 128, loss: 0.2315383404493332\n",
      "Epoch: 25, batch: 144, loss: 0.23423191905021667\n",
      "Epoch: 26, batch: 0, loss: 0.22830422222614288\n",
      "Epoch: 26, batch: 16, loss: 0.2697131335735321\n",
      "Epoch: 26, batch: 32, loss: 0.19069451093673706\n",
      "Epoch: 26, batch: 48, loss: 0.21246780455112457\n",
      "Epoch: 26, batch: 64, loss: 0.2654927670955658\n",
      "Epoch: 26, batch: 80, loss: 0.21157127618789673\n",
      "Epoch: 26, batch: 96, loss: 0.2851487994194031\n",
      "Epoch: 26, batch: 112, loss: 0.276976078748703\n",
      "Epoch: 26, batch: 128, loss: 0.2268172651529312\n",
      "Epoch: 26, batch: 144, loss: 0.23145383596420288\n",
      "Epoch: 27, batch: 0, loss: 0.22554761171340942\n",
      "Epoch: 27, batch: 16, loss: 0.26620393991470337\n",
      "Epoch: 27, batch: 32, loss: 0.18704329431056976\n",
      "Epoch: 27, batch: 48, loss: 0.2082846760749817\n",
      "Epoch: 27, batch: 64, loss: 0.2621256411075592\n",
      "Epoch: 27, batch: 80, loss: 0.20861713588237762\n",
      "Epoch: 27, batch: 96, loss: 0.28022944927215576\n",
      "Epoch: 27, batch: 112, loss: 0.2736949026584625\n",
      "Epoch: 27, batch: 128, loss: 0.2219439148902893\n",
      "Epoch: 27, batch: 144, loss: 0.22876212000846863\n",
      "Epoch: 28, batch: 0, loss: 0.22273141145706177\n",
      "Epoch: 28, batch: 16, loss: 0.2624605596065521\n",
      "Epoch: 28, batch: 32, loss: 0.18315263092517853\n",
      "Epoch: 28, batch: 48, loss: 0.20366637408733368\n",
      "Epoch: 28, batch: 64, loss: 0.25906214118003845\n",
      "Epoch: 28, batch: 80, loss: 0.20609457790851593\n",
      "Epoch: 28, batch: 96, loss: 0.27583450078964233\n",
      "Epoch: 28, batch: 112, loss: 0.2705017626285553\n",
      "Epoch: 28, batch: 128, loss: 0.21702755987644196\n",
      "Epoch: 28, batch: 144, loss: 0.22510406374931335\n",
      "Epoch: 29, batch: 0, loss: 0.21965736150741577\n",
      "Epoch: 29, batch: 16, loss: 0.2588069438934326\n",
      "Epoch: 29, batch: 32, loss: 0.17898808419704437\n",
      "Epoch: 29, batch: 48, loss: 0.19904351234436035\n",
      "Epoch: 29, batch: 64, loss: 0.2554458677768707\n",
      "Epoch: 29, batch: 80, loss: 0.20264071226119995\n",
      "Epoch: 29, batch: 96, loss: 0.2703736126422882\n",
      "Epoch: 29, batch: 112, loss: 0.26649925112724304\n",
      "Epoch: 29, batch: 128, loss: 0.21175865828990936\n",
      "Epoch: 29, batch: 144, loss: 0.22220590710639954\n",
      "Epoch: 30, batch: 0, loss: 0.2166605442762375\n",
      "Epoch: 30, batch: 16, loss: 0.2555709481239319\n",
      "Epoch: 30, batch: 32, loss: 0.1747816801071167\n",
      "Epoch: 30, batch: 48, loss: 0.19471095502376556\n",
      "Epoch: 30, batch: 64, loss: 0.2510889172554016\n",
      "Epoch: 30, batch: 80, loss: 0.1983051896095276\n",
      "Epoch: 30, batch: 96, loss: 0.2639126777648926\n",
      "Epoch: 30, batch: 112, loss: 0.2622229754924774\n",
      "Epoch: 30, batch: 128, loss: 0.20607133209705353\n",
      "Epoch: 30, batch: 144, loss: 0.21958309412002563\n",
      "Epoch: 31, batch: 0, loss: 0.21342776715755463\n",
      "Epoch: 31, batch: 16, loss: 0.25115904211997986\n",
      "Epoch: 31, batch: 32, loss: 0.17017406225204468\n",
      "Epoch: 31, batch: 48, loss: 0.18942643702030182\n",
      "Epoch: 31, batch: 64, loss: 0.2475159615278244\n",
      "Epoch: 31, batch: 80, loss: 0.19534534215927124\n",
      "Epoch: 31, batch: 96, loss: 0.25891366600990295\n",
      "Epoch: 31, batch: 112, loss: 0.2585285007953644\n",
      "Epoch: 31, batch: 128, loss: 0.2003588229417801\n",
      "Epoch: 31, batch: 144, loss: 0.2150518298149109\n",
      "Epoch: 32, batch: 0, loss: 0.20958487689495087\n",
      "Epoch: 32, batch: 16, loss: 0.24672077596187592\n",
      "Epoch: 32, batch: 32, loss: 0.16519419848918915\n",
      "Epoch: 32, batch: 48, loss: 0.184010848402977\n",
      "Epoch: 32, batch: 64, loss: 0.2433617115020752\n",
      "Epoch: 32, batch: 80, loss: 0.19142204523086548\n",
      "Epoch: 32, batch: 96, loss: 0.2524009644985199\n",
      "Epoch: 32, batch: 112, loss: 0.2538641095161438\n",
      "Epoch: 32, batch: 128, loss: 0.19397270679473877\n",
      "Epoch: 32, batch: 144, loss: 0.21034500002861023\n",
      "Epoch: 33, batch: 0, loss: 0.205704927444458\n",
      "Epoch: 33, batch: 16, loss: 0.24060221016407013\n",
      "Epoch: 33, batch: 32, loss: 0.15964455902576447\n",
      "Epoch: 33, batch: 48, loss: 0.17745225131511688\n",
      "Epoch: 33, batch: 64, loss: 0.239777073264122\n",
      "Epoch: 33, batch: 80, loss: 0.18807841837406158\n",
      "Epoch: 33, batch: 96, loss: 0.24696315824985504\n",
      "Epoch: 33, batch: 112, loss: 0.24858291447162628\n",
      "Epoch: 33, batch: 128, loss: 0.1876341849565506\n",
      "Epoch: 33, batch: 144, loss: 0.20763809978961945\n",
      "Epoch: 34, batch: 0, loss: 0.2017544060945511\n",
      "Epoch: 34, batch: 16, loss: 0.23909956216812134\n",
      "Epoch: 34, batch: 32, loss: 0.1543283760547638\n",
      "Epoch: 34, batch: 48, loss: 0.17276209592819214\n",
      "Epoch: 34, batch: 64, loss: 0.23337455093860626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, batch: 80, loss: 0.18126119673252106\n",
      "Epoch: 34, batch: 96, loss: 0.23725564777851105\n",
      "Epoch: 34, batch: 112, loss: 0.2428024560213089\n",
      "Epoch: 34, batch: 128, loss: 0.17989321053028107\n",
      "Epoch: 34, batch: 144, loss: 0.20449398458003998\n",
      "Epoch: 35, batch: 0, loss: 0.19769692420959473\n",
      "Epoch: 35, batch: 16, loss: 0.23283173143863678\n",
      "Epoch: 35, batch: 32, loss: 0.14820705354213715\n",
      "Epoch: 35, batch: 48, loss: 0.1656017154455185\n",
      "Epoch: 35, batch: 64, loss: 0.22923563420772552\n",
      "Epoch: 35, batch: 80, loss: 0.17819558084011078\n",
      "Epoch: 35, batch: 96, loss: 0.2322722226381302\n",
      "Epoch: 35, batch: 112, loss: 0.23805153369903564\n",
      "Epoch: 35, batch: 128, loss: 0.17292232811450958\n",
      "Epoch: 35, batch: 144, loss: 0.19820445775985718\n",
      "Epoch: 36, batch: 0, loss: 0.19231124222278595\n",
      "Epoch: 36, batch: 16, loss: 0.2270582914352417\n",
      "Epoch: 36, batch: 32, loss: 0.14183813333511353\n",
      "Epoch: 36, batch: 48, loss: 0.15855886042118073\n",
      "Epoch: 36, batch: 64, loss: 0.22439365088939667\n",
      "Epoch: 36, batch: 80, loss: 0.17290811240673065\n",
      "Epoch: 36, batch: 96, loss: 0.22311699390411377\n",
      "Epoch: 36, batch: 112, loss: 0.23126481473445892\n",
      "Epoch: 36, batch: 128, loss: 0.1649758368730545\n",
      "Epoch: 36, batch: 144, loss: 0.19632306694984436\n",
      "Epoch: 37, batch: 0, loss: 0.18785971403121948\n",
      "Epoch: 37, batch: 16, loss: 0.22191566228866577\n",
      "Epoch: 37, batch: 32, loss: 0.13522325456142426\n",
      "Epoch: 37, batch: 48, loss: 0.1509511023759842\n",
      "Epoch: 37, batch: 64, loss: 0.2197597473859787\n",
      "Epoch: 37, batch: 80, loss: 0.16862237453460693\n",
      "Epoch: 37, batch: 96, loss: 0.21633075177669525\n",
      "Epoch: 37, batch: 112, loss: 0.2252226620912552\n",
      "Epoch: 37, batch: 128, loss: 0.15683096647262573\n",
      "Epoch: 37, batch: 144, loss: 0.19304202497005463\n",
      "Epoch: 38, batch: 0, loss: 0.182627871632576\n",
      "Epoch: 38, batch: 16, loss: 0.21860910952091217\n",
      "Epoch: 38, batch: 32, loss: 0.12842987477779388\n",
      "Epoch: 38, batch: 48, loss: 0.14380556344985962\n",
      "Epoch: 38, batch: 64, loss: 0.2143590897321701\n",
      "Epoch: 38, batch: 80, loss: 0.1631719172000885\n",
      "Epoch: 38, batch: 96, loss: 0.2075546532869339\n",
      "Epoch: 38, batch: 112, loss: 0.21927684545516968\n",
      "Epoch: 38, batch: 128, loss: 0.148254856467247\n",
      "Epoch: 38, batch: 144, loss: 0.18856678903102875\n",
      "Epoch: 39, batch: 0, loss: 0.1774776577949524\n",
      "Epoch: 39, batch: 16, loss: 0.21117807924747467\n",
      "Epoch: 39, batch: 32, loss: 0.12124905735254288\n",
      "Epoch: 39, batch: 48, loss: 0.13502322137355804\n",
      "Epoch: 39, batch: 64, loss: 0.21053533256053925\n",
      "Epoch: 39, batch: 80, loss: 0.15927793085575104\n",
      "Epoch: 39, batch: 96, loss: 0.20089702308177948\n",
      "Epoch: 39, batch: 112, loss: 0.21242506802082062\n",
      "Epoch: 39, batch: 128, loss: 0.14001582562923431\n",
      "Epoch: 39, batch: 144, loss: 0.18726596236228943\n",
      "Epoch: 40, batch: 0, loss: 0.17234157025814056\n",
      "Epoch: 40, batch: 16, loss: 0.20870763063430786\n",
      "Epoch: 40, batch: 32, loss: 0.1142951175570488\n",
      "Epoch: 40, batch: 48, loss: 0.12757275998592377\n",
      "Epoch: 40, batch: 64, loss: 0.2058117389678955\n",
      "Epoch: 40, batch: 80, loss: 0.15430735051631927\n",
      "Epoch: 40, batch: 96, loss: 0.19243179261684418\n",
      "Epoch: 40, batch: 112, loss: 0.2068464607000351\n",
      "Epoch: 40, batch: 128, loss: 0.13096097111701965\n",
      "Epoch: 40, batch: 144, loss: 0.18290895223617554\n",
      "Epoch: 41, batch: 0, loss: 0.1672154664993286\n",
      "Epoch: 41, batch: 16, loss: 0.20305569469928741\n",
      "Epoch: 41, batch: 32, loss: 0.10714779049158096\n",
      "Epoch: 41, batch: 48, loss: 0.11954648047685623\n",
      "Epoch: 41, batch: 64, loss: 0.2002078890800476\n",
      "Epoch: 41, batch: 80, loss: 0.14887909591197968\n",
      "Epoch: 41, batch: 96, loss: 0.18340016901493073\n",
      "Epoch: 41, batch: 112, loss: 0.19841335713863373\n",
      "Epoch: 41, batch: 128, loss: 0.12320790439844131\n",
      "Epoch: 41, batch: 144, loss: 0.18201442062854767\n",
      "Epoch: 42, batch: 0, loss: 0.16248224675655365\n",
      "Epoch: 42, batch: 16, loss: 0.19778013229370117\n",
      "Epoch: 42, batch: 32, loss: 0.10058492422103882\n",
      "Epoch: 42, batch: 48, loss: 0.1117435097694397\n",
      "Epoch: 42, batch: 64, loss: 0.19646809995174408\n",
      "Epoch: 42, batch: 80, loss: 0.14412568509578705\n",
      "Epoch: 42, batch: 96, loss: 0.17577017843723297\n",
      "Epoch: 42, batch: 112, loss: 0.19344520568847656\n",
      "Epoch: 42, batch: 128, loss: 0.11476100236177444\n",
      "Epoch: 42, batch: 144, loss: 0.17875458300113678\n",
      "Epoch: 43, batch: 0, loss: 0.15756364166736603\n",
      "Epoch: 43, batch: 16, loss: 0.1940060406923294\n",
      "Epoch: 43, batch: 32, loss: 0.09388934820890427\n",
      "Epoch: 43, batch: 48, loss: 0.10436298698186874\n",
      "Epoch: 43, batch: 64, loss: 0.19115793704986572\n",
      "Epoch: 43, batch: 80, loss: 0.13879787921905518\n",
      "Epoch: 43, batch: 96, loss: 0.16771401464939117\n",
      "Epoch: 43, batch: 112, loss: 0.18756036460399628\n",
      "Epoch: 43, batch: 128, loss: 0.10669863969087601\n",
      "Epoch: 43, batch: 144, loss: 0.1753673404455185\n",
      "Epoch: 44, batch: 0, loss: 0.15312793850898743\n",
      "Epoch: 44, batch: 16, loss: 0.1894664764404297\n",
      "Epoch: 44, batch: 32, loss: 0.08765425533056259\n",
      "Epoch: 44, batch: 48, loss: 0.0973304808139801\n",
      "Epoch: 44, batch: 64, loss: 0.1859121173620224\n",
      "Epoch: 44, batch: 80, loss: 0.13289761543273926\n",
      "Epoch: 44, batch: 96, loss: 0.15877635776996613\n",
      "Epoch: 44, batch: 112, loss: 0.18133719265460968\n",
      "Epoch: 44, batch: 128, loss: 0.09920075535774231\n",
      "Epoch: 44, batch: 144, loss: 0.1728723645210266\n",
      "Epoch: 45, batch: 0, loss: 0.14882002770900726\n",
      "Epoch: 45, batch: 16, loss: 0.18478047847747803\n",
      "Epoch: 45, batch: 32, loss: 0.08181891590356827\n",
      "Epoch: 45, batch: 48, loss: 0.09049614518880844\n",
      "Epoch: 45, batch: 64, loss: 0.18154515326023102\n",
      "Epoch: 45, batch: 80, loss: 0.12772081792354584\n",
      "Epoch: 45, batch: 96, loss: 0.15047723054885864\n",
      "Epoch: 45, batch: 112, loss: 0.17528392374515533\n",
      "Epoch: 45, batch: 128, loss: 0.09242400527000427\n",
      "Epoch: 45, batch: 144, loss: 0.17165713012218475\n",
      "Epoch: 46, batch: 0, loss: 0.14497271180152893\n",
      "Epoch: 46, batch: 16, loss: 0.18078483641147614\n",
      "Epoch: 46, batch: 32, loss: 0.07649048417806625\n",
      "Epoch: 46, batch: 48, loss: 0.08414895087480545\n",
      "Epoch: 46, batch: 64, loss: 0.17790518701076508\n",
      "Epoch: 46, batch: 80, loss: 0.12334262579679489\n",
      "Epoch: 46, batch: 96, loss: 0.14304915070533752\n",
      "Epoch: 46, batch: 112, loss: 0.17039424180984497\n",
      "Epoch: 46, batch: 128, loss: 0.08563268929719925\n",
      "Epoch: 46, batch: 144, loss: 0.16671401262283325\n",
      "Epoch: 47, batch: 0, loss: 0.1408945918083191\n",
      "Epoch: 47, batch: 16, loss: 0.17563079297542572\n",
      "Epoch: 47, batch: 32, loss: 0.07166822999715805\n",
      "Epoch: 47, batch: 48, loss: 0.07855058461427689\n",
      "Epoch: 47, batch: 64, loss: 0.17273853719234467\n",
      "Epoch: 47, batch: 80, loss: 0.11772938817739487\n",
      "Epoch: 47, batch: 96, loss: 0.1350320279598236\n",
      "Epoch: 47, batch: 112, loss: 0.16506581008434296\n",
      "Epoch: 47, batch: 128, loss: 0.07966937124729156\n",
      "Epoch: 47, batch: 144, loss: 0.1643119603395462\n",
      "Epoch: 48, batch: 0, loss: 0.13765239715576172\n",
      "Epoch: 48, batch: 16, loss: 0.17182420194149017\n",
      "Epoch: 48, batch: 32, loss: 0.06737034767866135\n",
      "Epoch: 48, batch: 48, loss: 0.07328011095523834\n",
      "Epoch: 48, batch: 64, loss: 0.16956649720668793\n",
      "Epoch: 48, batch: 80, loss: 0.11354991048574448\n",
      "Epoch: 48, batch: 96, loss: 0.12849603593349457\n",
      "Epoch: 48, batch: 112, loss: 0.16105683147907257\n",
      "Epoch: 48, batch: 128, loss: 0.07426999509334564\n",
      "Epoch: 48, batch: 144, loss: 0.16240234673023224\n",
      "Epoch: 49, batch: 0, loss: 0.13472464680671692\n",
      "Epoch: 49, batch: 16, loss: 0.16956494748592377\n",
      "Epoch: 49, batch: 32, loss: 0.06332244724035263\n",
      "Epoch: 49, batch: 48, loss: 0.068416066467762\n",
      "Epoch: 49, batch: 64, loss: 0.16719019412994385\n",
      "Epoch: 49, batch: 80, loss: 0.10993427038192749\n",
      "Epoch: 49, batch: 96, loss: 0.12276622653007507\n",
      "Epoch: 49, batch: 112, loss: 0.15794436633586884\n",
      "Epoch: 49, batch: 128, loss: 0.06953208148479462\n",
      "Epoch: 49, batch: 144, loss: 0.1604108214378357\n",
      "Epoch: 50, batch: 0, loss: 0.13203643262386322\n",
      "Epoch: 50, batch: 16, loss: 0.1671488881111145\n",
      "Epoch: 50, batch: 32, loss: 0.05965717136859894\n",
      "Epoch: 50, batch: 48, loss: 0.06408786028623581\n",
      "Epoch: 50, batch: 64, loss: 0.16415996849536896\n",
      "Epoch: 50, batch: 80, loss: 0.10570484399795532\n",
      "Epoch: 50, batch: 96, loss: 0.11686688661575317\n",
      "Epoch: 50, batch: 112, loss: 0.1554395705461502\n",
      "Epoch: 50, batch: 128, loss: 0.06528476625680923\n",
      "Epoch: 50, batch: 144, loss: 0.15742744505405426\n",
      "Epoch: 51, batch: 0, loss: 0.12974713742733002\n",
      "Epoch: 51, batch: 16, loss: 0.16390331089496613\n",
      "Epoch: 51, batch: 32, loss: 0.05648115649819374\n",
      "Epoch: 51, batch: 48, loss: 0.060316815972328186\n",
      "Epoch: 51, batch: 64, loss: 0.1602032631635666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, batch: 80, loss: 0.10088757425546646\n",
      "Epoch: 51, batch: 96, loss: 0.11071667820215225\n",
      "Epoch: 51, batch: 112, loss: 0.1529018133878708\n",
      "Epoch: 51, batch: 128, loss: 0.06138971820473671\n",
      "Epoch: 51, batch: 144, loss: 0.15354350209236145\n",
      "Epoch: 52, batch: 0, loss: 0.1277519017457962\n",
      "Epoch: 52, batch: 16, loss: 0.16034136712551117\n",
      "Epoch: 52, batch: 32, loss: 0.05385814607143402\n",
      "Epoch: 52, batch: 48, loss: 0.05700197443366051\n",
      "Epoch: 52, batch: 64, loss: 0.1563565880060196\n",
      "Epoch: 52, batch: 80, loss: 0.0963074341416359\n",
      "Epoch: 52, batch: 96, loss: 0.10485974699258804\n",
      "Epoch: 52, batch: 112, loss: 0.1504429429769516\n",
      "Epoch: 52, batch: 128, loss: 0.05799200013279915\n",
      "Epoch: 52, batch: 144, loss: 0.15008698403835297\n",
      "Epoch: 53, batch: 0, loss: 0.12604601681232452\n",
      "Epoch: 53, batch: 16, loss: 0.15638063848018646\n",
      "Epoch: 53, batch: 32, loss: 0.051465705037117004\n",
      "Epoch: 53, batch: 48, loss: 0.05388980731368065\n",
      "Epoch: 53, batch: 64, loss: 0.1529160887002945\n",
      "Epoch: 53, batch: 80, loss: 0.09167846292257309\n",
      "Epoch: 53, batch: 96, loss: 0.09983222931623459\n",
      "Epoch: 53, batch: 112, loss: 0.14945857226848602\n",
      "Epoch: 53, batch: 128, loss: 0.05466092750430107\n",
      "Epoch: 53, batch: 144, loss: 0.14451265335083008\n",
      "Epoch: 54, batch: 0, loss: 0.12415096908807755\n",
      "Epoch: 54, batch: 16, loss: 0.15183301270008087\n",
      "Epoch: 54, batch: 32, loss: 0.049144431948661804\n",
      "Epoch: 54, batch: 48, loss: 0.05125533416867256\n",
      "Epoch: 54, batch: 64, loss: 0.14775021374225616\n",
      "Epoch: 54, batch: 80, loss: 0.08638588339090347\n",
      "Epoch: 54, batch: 96, loss: 0.09434735029935837\n",
      "Epoch: 54, batch: 112, loss: 0.14769770205020905\n",
      "Epoch: 54, batch: 128, loss: 0.0516381710767746\n",
      "Epoch: 54, batch: 144, loss: 0.13847576081752777\n",
      "Epoch: 55, batch: 0, loss: 0.12272492051124573\n",
      "Epoch: 55, batch: 16, loss: 0.14665758609771729\n",
      "Epoch: 55, batch: 32, loss: 0.04710381105542183\n",
      "Epoch: 55, batch: 48, loss: 0.04894747957587242\n",
      "Epoch: 55, batch: 64, loss: 0.14273647964000702\n",
      "Epoch: 55, batch: 80, loss: 0.0806046798825264\n",
      "Epoch: 55, batch: 96, loss: 0.08797949552536011\n",
      "Epoch: 55, batch: 112, loss: 0.14390863478183746\n",
      "Epoch: 55, batch: 128, loss: 0.049071893095970154\n",
      "Epoch: 55, batch: 144, loss: 0.13339895009994507\n",
      "Epoch: 56, batch: 0, loss: 0.12162691354751587\n",
      "Epoch: 56, batch: 16, loss: 0.14121396839618683\n",
      "Epoch: 56, batch: 32, loss: 0.04547715187072754\n",
      "Epoch: 56, batch: 48, loss: 0.046743664890527725\n",
      "Epoch: 56, batch: 64, loss: 0.1392381191253662\n",
      "Epoch: 56, batch: 80, loss: 0.07607763260602951\n",
      "Epoch: 56, batch: 96, loss: 0.08264557272195816\n",
      "Epoch: 56, batch: 112, loss: 0.14021293818950653\n",
      "Epoch: 56, batch: 128, loss: 0.04702935740351677\n",
      "Epoch: 56, batch: 144, loss: 0.13051581382751465\n",
      "Epoch: 57, batch: 0, loss: 0.12079279869794846\n",
      "Epoch: 57, batch: 16, loss: 0.13653253018856049\n",
      "Epoch: 57, batch: 32, loss: 0.04392724111676216\n",
      "Epoch: 57, batch: 48, loss: 0.04451115429401398\n",
      "Epoch: 57, batch: 64, loss: 0.13696740567684174\n",
      "Epoch: 57, batch: 80, loss: 0.07221292704343796\n",
      "Epoch: 57, batch: 96, loss: 0.07796893268823624\n",
      "Epoch: 57, batch: 112, loss: 0.13713935017585754\n",
      "Epoch: 57, batch: 128, loss: 0.045393843203783035\n",
      "Epoch: 57, batch: 144, loss: 0.1287277787923813\n",
      "Epoch: 58, batch: 0, loss: 0.11999306827783585\n",
      "Epoch: 58, batch: 16, loss: 0.13214220106601715\n",
      "Epoch: 58, batch: 32, loss: 0.042443204671144485\n",
      "Epoch: 58, batch: 48, loss: 0.042473819106817245\n",
      "Epoch: 58, batch: 64, loss: 0.13472622632980347\n",
      "Epoch: 58, batch: 80, loss: 0.06856531649827957\n",
      "Epoch: 58, batch: 96, loss: 0.0737685114145279\n",
      "Epoch: 58, batch: 112, loss: 0.13458101451396942\n",
      "Epoch: 58, batch: 128, loss: 0.043814364820718765\n",
      "Epoch: 58, batch: 144, loss: 0.12622714042663574\n",
      "Epoch: 59, batch: 0, loss: 0.11943420022726059\n",
      "Epoch: 59, batch: 16, loss: 0.12820062041282654\n",
      "Epoch: 59, batch: 32, loss: 0.04115566983819008\n",
      "Epoch: 59, batch: 48, loss: 0.04076329991221428\n",
      "Epoch: 59, batch: 64, loss: 0.1320924013853073\n",
      "Epoch: 59, batch: 80, loss: 0.06511034816503525\n",
      "Epoch: 59, batch: 96, loss: 0.0699160173535347\n",
      "Epoch: 59, batch: 112, loss: 0.132363423705101\n",
      "Epoch: 59, batch: 128, loss: 0.042208489030599594\n",
      "Epoch: 59, batch: 144, loss: 0.12319372594356537\n",
      "Epoch: 60, batch: 0, loss: 0.11928319185972214\n",
      "Epoch: 60, batch: 16, loss: 0.12491139769554138\n",
      "Epoch: 60, batch: 32, loss: 0.040106553584337234\n",
      "Epoch: 60, batch: 48, loss: 0.03916330263018608\n",
      "Epoch: 60, batch: 64, loss: 0.1304207295179367\n",
      "Epoch: 60, batch: 80, loss: 0.0626261830329895\n",
      "Epoch: 60, batch: 96, loss: 0.06698977947235107\n",
      "Epoch: 60, batch: 112, loss: 0.1311722695827484\n",
      "Epoch: 60, batch: 128, loss: 0.04072631523013115\n",
      "Epoch: 60, batch: 144, loss: 0.11923941969871521\n",
      "Epoch: 61, batch: 0, loss: 0.11883056908845901\n",
      "Epoch: 61, batch: 16, loss: 0.12061334401369095\n",
      "Epoch: 61, batch: 32, loss: 0.03892706334590912\n",
      "Epoch: 61, batch: 48, loss: 0.03777487203478813\n",
      "Epoch: 61, batch: 64, loss: 0.12692798674106598\n",
      "Epoch: 61, batch: 80, loss: 0.0582718700170517\n",
      "Epoch: 61, batch: 96, loss: 0.06270318478345871\n",
      "Epoch: 61, batch: 112, loss: 0.12773604691028595\n",
      "Epoch: 61, batch: 128, loss: 0.03965235874056816\n",
      "Epoch: 61, batch: 144, loss: 0.11603116989135742\n",
      "Epoch: 62, batch: 0, loss: 0.11880313605070114\n",
      "Epoch: 62, batch: 16, loss: 0.11538141220808029\n",
      "Epoch: 62, batch: 32, loss: 0.03801162913441658\n",
      "Epoch: 62, batch: 48, loss: 0.03639184683561325\n",
      "Epoch: 62, batch: 64, loss: 0.12421351671218872\n",
      "Epoch: 62, batch: 80, loss: 0.05473015829920769\n",
      "Epoch: 62, batch: 96, loss: 0.05914825201034546\n",
      "Epoch: 62, batch: 112, loss: 0.12434723228216171\n",
      "Epoch: 62, batch: 128, loss: 0.03869324550032616\n",
      "Epoch: 62, batch: 144, loss: 0.1135442778468132\n",
      "Epoch: 63, batch: 0, loss: 0.11889266967773438\n",
      "Epoch: 63, batch: 16, loss: 0.11149699240922928\n",
      "Epoch: 63, batch: 32, loss: 0.03732460364699364\n",
      "Epoch: 63, batch: 48, loss: 0.035086896270513535\n",
      "Epoch: 63, batch: 64, loss: 0.12262502312660217\n",
      "Epoch: 63, batch: 80, loss: 0.05225749313831329\n",
      "Epoch: 63, batch: 96, loss: 0.05641472339630127\n",
      "Epoch: 63, batch: 112, loss: 0.12190953642129898\n",
      "Epoch: 63, batch: 128, loss: 0.037940043956041336\n",
      "Epoch: 63, batch: 144, loss: 0.11253269761800766\n",
      "Epoch: 64, batch: 0, loss: 0.11888144165277481\n",
      "Epoch: 64, batch: 16, loss: 0.10849326848983765\n",
      "Epoch: 64, batch: 32, loss: 0.03653443232178688\n",
      "Epoch: 64, batch: 48, loss: 0.03384070843458176\n",
      "Epoch: 64, batch: 64, loss: 0.12130564451217651\n",
      "Epoch: 64, batch: 80, loss: 0.05023913085460663\n",
      "Epoch: 64, batch: 96, loss: 0.05433319881558418\n",
      "Epoch: 64, batch: 112, loss: 0.12087231874465942\n",
      "Epoch: 64, batch: 128, loss: 0.036933284252882004\n",
      "Epoch: 64, batch: 144, loss: 0.11037782579660416\n",
      "Epoch: 65, batch: 0, loss: 0.11896421760320663\n",
      "Epoch: 65, batch: 16, loss: 0.10640037059783936\n",
      "Epoch: 65, batch: 32, loss: 0.03569149598479271\n",
      "Epoch: 65, batch: 48, loss: 0.03279534727334976\n",
      "Epoch: 65, batch: 64, loss: 0.11963949352502823\n",
      "Epoch: 65, batch: 80, loss: 0.04793858900666237\n",
      "Epoch: 65, batch: 96, loss: 0.05204831436276436\n",
      "Epoch: 65, batch: 112, loss: 0.1193055734038353\n",
      "Epoch: 65, batch: 128, loss: 0.036180946975946426\n",
      "Epoch: 65, batch: 144, loss: 0.10855124890804291\n",
      "Epoch: 66, batch: 0, loss: 0.11911719292402267\n",
      "Epoch: 66, batch: 16, loss: 0.10365716367959976\n",
      "Epoch: 66, batch: 32, loss: 0.03497040644288063\n",
      "Epoch: 66, batch: 48, loss: 0.03185757249593735\n",
      "Epoch: 66, batch: 64, loss: 0.11757882684469223\n",
      "Epoch: 66, batch: 80, loss: 0.0455937385559082\n",
      "Epoch: 66, batch: 96, loss: 0.049846455454826355\n",
      "Epoch: 66, batch: 112, loss: 0.11759763956069946\n",
      "Epoch: 66, batch: 128, loss: 0.035378728061914444\n",
      "Epoch: 66, batch: 144, loss: 0.10601139813661575\n",
      "Epoch: 67, batch: 0, loss: 0.11967766284942627\n",
      "Epoch: 67, batch: 16, loss: 0.1012556329369545\n",
      "Epoch: 67, batch: 32, loss: 0.03447357192635536\n",
      "Epoch: 67, batch: 48, loss: 0.031015442684292793\n",
      "Epoch: 67, batch: 64, loss: 0.11590277403593063\n",
      "Epoch: 67, batch: 80, loss: 0.04367387667298317\n",
      "Epoch: 67, batch: 96, loss: 0.04794946685433388\n",
      "Epoch: 67, batch: 112, loss: 0.11594294756650925\n",
      "Epoch: 67, batch: 128, loss: 0.0347723625600338\n",
      "Epoch: 67, batch: 144, loss: 0.10427667200565338\n",
      "Epoch: 68, batch: 0, loss: 0.11984468251466751\n",
      "Epoch: 68, batch: 16, loss: 0.09884066134691238\n",
      "Epoch: 68, batch: 32, loss: 0.0338483564555645\n",
      "Epoch: 68, batch: 48, loss: 0.030102549120783806\n",
      "Epoch: 68, batch: 64, loss: 0.11465096473693848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, batch: 80, loss: 0.041696697473526\n",
      "Epoch: 68, batch: 96, loss: 0.045988429337739944\n",
      "Epoch: 68, batch: 112, loss: 0.11435768008232117\n",
      "Epoch: 68, batch: 128, loss: 0.034277234226465225\n",
      "Epoch: 68, batch: 144, loss: 0.10279885679483414\n",
      "Epoch: 69, batch: 0, loss: 0.12006640434265137\n",
      "Epoch: 69, batch: 16, loss: 0.09638618677854538\n",
      "Epoch: 69, batch: 32, loss: 0.033248405903577805\n",
      "Epoch: 69, batch: 48, loss: 0.029288649559020996\n",
      "Epoch: 69, batch: 64, loss: 0.11312706023454666\n",
      "Epoch: 69, batch: 80, loss: 0.03978591412305832\n",
      "Epoch: 69, batch: 96, loss: 0.044212788343429565\n",
      "Epoch: 69, batch: 112, loss: 0.1126970574259758\n",
      "Epoch: 69, batch: 128, loss: 0.0337575264275074\n",
      "Epoch: 69, batch: 144, loss: 0.10074342042207718\n",
      "Epoch: 70, batch: 0, loss: 0.12044215947389603\n",
      "Epoch: 70, batch: 16, loss: 0.0943254604935646\n",
      "Epoch: 70, batch: 32, loss: 0.03273046389222145\n",
      "Epoch: 70, batch: 48, loss: 0.028542963787913322\n",
      "Epoch: 70, batch: 64, loss: 0.11179220676422119\n",
      "Epoch: 70, batch: 80, loss: 0.03803816810250282\n",
      "Epoch: 70, batch: 96, loss: 0.04253285750746727\n",
      "Epoch: 70, batch: 112, loss: 0.11116010695695877\n",
      "Epoch: 70, batch: 128, loss: 0.03336401283740997\n",
      "Epoch: 70, batch: 144, loss: 0.09922321885824203\n",
      "Epoch: 71, batch: 0, loss: 0.12082704156637192\n",
      "Epoch: 71, batch: 16, loss: 0.09195587784051895\n",
      "Epoch: 71, batch: 32, loss: 0.03227822110056877\n",
      "Epoch: 71, batch: 48, loss: 0.027840323746204376\n",
      "Epoch: 71, batch: 64, loss: 0.11038283258676529\n",
      "Epoch: 71, batch: 80, loss: 0.03649338707327843\n",
      "Epoch: 71, batch: 96, loss: 0.04111756756901741\n",
      "Epoch: 71, batch: 112, loss: 0.10992450267076492\n",
      "Epoch: 71, batch: 128, loss: 0.03285618871450424\n",
      "Epoch: 71, batch: 144, loss: 0.09730265289545059\n",
      "Epoch: 72, batch: 0, loss: 0.1215875968337059\n",
      "Epoch: 72, batch: 16, loss: 0.09043294191360474\n",
      "Epoch: 72, batch: 32, loss: 0.031971823424100876\n",
      "Epoch: 72, batch: 48, loss: 0.027249546721577644\n",
      "Epoch: 72, batch: 64, loss: 0.10918337851762772\n",
      "Epoch: 72, batch: 80, loss: 0.03535427898168564\n",
      "Epoch: 72, batch: 96, loss: 0.0400288961827755\n",
      "Epoch: 72, batch: 112, loss: 0.10941264778375626\n",
      "Epoch: 72, batch: 128, loss: 0.03231227025389671\n",
      "Epoch: 72, batch: 144, loss: 0.09554749727249146\n",
      "Epoch: 73, batch: 0, loss: 0.12188779562711716\n",
      "Epoch: 73, batch: 16, loss: 0.08910354226827621\n",
      "Epoch: 73, batch: 32, loss: 0.0314314030110836\n",
      "Epoch: 73, batch: 48, loss: 0.026664696633815765\n",
      "Epoch: 73, batch: 64, loss: 0.1079544648528099\n",
      "Epoch: 73, batch: 80, loss: 0.03385406360030174\n",
      "Epoch: 73, batch: 96, loss: 0.03866526857018471\n",
      "Epoch: 73, batch: 112, loss: 0.10826856642961502\n",
      "Epoch: 73, batch: 128, loss: 0.031936164945364\n",
      "Epoch: 73, batch: 144, loss: 0.09382995963096619\n",
      "Epoch: 74, batch: 0, loss: 0.12222975492477417\n",
      "Epoch: 74, batch: 16, loss: 0.08702073246240616\n",
      "Epoch: 74, batch: 32, loss: 0.030944637954235077\n",
      "Epoch: 74, batch: 48, loss: 0.026047592982649803\n",
      "Epoch: 74, batch: 64, loss: 0.1066923439502716\n",
      "Epoch: 74, batch: 80, loss: 0.032270606607198715\n",
      "Epoch: 74, batch: 96, loss: 0.037269238382577896\n",
      "Epoch: 74, batch: 112, loss: 0.10653723031282425\n",
      "Epoch: 74, batch: 128, loss: 0.031707193702459335\n",
      "Epoch: 74, batch: 144, loss: 0.09217990934848785\n",
      "Epoch: 75, batch: 0, loss: 0.1226782575249672\n",
      "Epoch: 75, batch: 16, loss: 0.08470935374498367\n",
      "Epoch: 75, batch: 32, loss: 0.030582718551158905\n",
      "Epoch: 75, batch: 48, loss: 0.02550239861011505\n",
      "Epoch: 75, batch: 64, loss: 0.10526993125677109\n",
      "Epoch: 75, batch: 80, loss: 0.03081650845706463\n",
      "Epoch: 75, batch: 96, loss: 0.036058567464351654\n",
      "Epoch: 75, batch: 112, loss: 0.1048668920993805\n",
      "Epoch: 75, batch: 128, loss: 0.03139771893620491\n",
      "Epoch: 75, batch: 144, loss: 0.0903710201382637\n",
      "Epoch: 76, batch: 0, loss: 0.12347964197397232\n",
      "Epoch: 76, batch: 16, loss: 0.0831252709031105\n",
      "Epoch: 76, batch: 32, loss: 0.03041485883295536\n",
      "Epoch: 76, batch: 48, loss: 0.02501165308058262\n",
      "Epoch: 76, batch: 64, loss: 0.10423924773931503\n",
      "Epoch: 76, batch: 80, loss: 0.02979533188045025\n",
      "Epoch: 76, batch: 96, loss: 0.035117413848638535\n",
      "Epoch: 76, batch: 112, loss: 0.10433164238929749\n",
      "Epoch: 76, batch: 128, loss: 0.030922912061214447\n",
      "Epoch: 76, batch: 144, loss: 0.08805494755506516\n",
      "Epoch: 77, batch: 0, loss: 0.12402337789535522\n",
      "Epoch: 77, batch: 16, loss: 0.0814773365855217\n",
      "Epoch: 77, batch: 32, loss: 0.029984720051288605\n",
      "Epoch: 77, batch: 48, loss: 0.02460341341793537\n",
      "Epoch: 77, batch: 64, loss: 0.10265001654624939\n",
      "Epoch: 77, batch: 80, loss: 0.028388574719429016\n",
      "Epoch: 77, batch: 96, loss: 0.03402151167392731\n",
      "Epoch: 77, batch: 112, loss: 0.10272303968667984\n",
      "Epoch: 77, batch: 128, loss: 0.030714264139533043\n",
      "Epoch: 77, batch: 144, loss: 0.08636346459388733\n",
      "Epoch: 78, batch: 0, loss: 0.12448828667402267\n",
      "Epoch: 78, batch: 16, loss: 0.07944007962942123\n",
      "Epoch: 78, batch: 32, loss: 0.029644198715686798\n",
      "Epoch: 78, batch: 48, loss: 0.02406899444758892\n",
      "Epoch: 78, batch: 64, loss: 0.10168123990297318\n",
      "Epoch: 78, batch: 80, loss: 0.027123337611556053\n",
      "Epoch: 78, batch: 96, loss: 0.032959479838609695\n",
      "Epoch: 78, batch: 112, loss: 0.10091104358434677\n",
      "Epoch: 78, batch: 128, loss: 0.030692992731928825\n",
      "Epoch: 78, batch: 144, loss: 0.08545398712158203\n",
      "Epoch: 79, batch: 0, loss: 0.12496434897184372\n",
      "Epoch: 79, batch: 16, loss: 0.07745466381311417\n",
      "Epoch: 79, batch: 32, loss: 0.029425492510199547\n",
      "Epoch: 79, batch: 48, loss: 0.02356681413948536\n",
      "Epoch: 79, batch: 64, loss: 0.10065337270498276\n",
      "Epoch: 79, batch: 80, loss: 0.026108218356966972\n",
      "Epoch: 79, batch: 96, loss: 0.03216024860739708\n",
      "Epoch: 79, batch: 112, loss: 0.09949054569005966\n",
      "Epoch: 79, batch: 128, loss: 0.03053147904574871\n",
      "Epoch: 79, batch: 144, loss: 0.08426285535097122\n",
      "Epoch: 80, batch: 0, loss: 0.12572552263736725\n",
      "Epoch: 80, batch: 16, loss: 0.07631657272577286\n",
      "Epoch: 80, batch: 32, loss: 0.029309755191206932\n",
      "Epoch: 80, batch: 48, loss: 0.02316422201693058\n",
      "Epoch: 80, batch: 64, loss: 0.09997648745775223\n",
      "Epoch: 80, batch: 80, loss: 0.025418512523174286\n",
      "Epoch: 80, batch: 96, loss: 0.031518179923295975\n",
      "Epoch: 80, batch: 112, loss: 0.09870604425668716\n",
      "Epoch: 80, batch: 128, loss: 0.030349494889378548\n",
      "Epoch: 80, batch: 144, loss: 0.08342188596725464\n",
      "Epoch: 81, batch: 0, loss: 0.12605449557304382\n",
      "Epoch: 81, batch: 16, loss: 0.07546614110469818\n",
      "Epoch: 81, batch: 32, loss: 0.02897484414279461\n",
      "Epoch: 81, batch: 48, loss: 0.022729916498064995\n",
      "Epoch: 81, batch: 64, loss: 0.09944095462560654\n",
      "Epoch: 81, batch: 80, loss: 0.024628853425383568\n",
      "Epoch: 81, batch: 96, loss: 0.030786819756031036\n",
      "Epoch: 81, batch: 112, loss: 0.0979851484298706\n",
      "Epoch: 81, batch: 128, loss: 0.030194884166121483\n",
      "Epoch: 81, batch: 144, loss: 0.08245591074228287\n",
      "Epoch: 82, batch: 0, loss: 0.1263457089662552\n",
      "Epoch: 82, batch: 16, loss: 0.07429109513759613\n",
      "Epoch: 82, batch: 32, loss: 0.02862250618636608\n",
      "Epoch: 82, batch: 48, loss: 0.022306017577648163\n",
      "Epoch: 82, batch: 64, loss: 0.09863889217376709\n",
      "Epoch: 82, batch: 80, loss: 0.023722505196928978\n",
      "Epoch: 82, batch: 96, loss: 0.030019747093319893\n",
      "Epoch: 82, batch: 112, loss: 0.09695553779602051\n",
      "Epoch: 82, batch: 128, loss: 0.030131511390209198\n",
      "Epoch: 82, batch: 144, loss: 0.08141078054904938\n",
      "Epoch: 83, batch: 0, loss: 0.12675857543945312\n",
      "Epoch: 83, batch: 16, loss: 0.07286161929368973\n",
      "Epoch: 83, batch: 32, loss: 0.028353022411465645\n",
      "Epoch: 83, batch: 48, loss: 0.02198774926364422\n",
      "Epoch: 83, batch: 64, loss: 0.09742317348718643\n",
      "Epoch: 83, batch: 80, loss: 0.022836247459053993\n",
      "Epoch: 83, batch: 96, loss: 0.029421366751194\n",
      "Epoch: 83, batch: 112, loss: 0.09586114436388016\n",
      "Epoch: 83, batch: 128, loss: 0.02989758364856243\n",
      "Epoch: 83, batch: 144, loss: 0.07971063256263733\n",
      "Epoch: 84, batch: 0, loss: 0.12757688760757446\n",
      "Epoch: 84, batch: 16, loss: 0.07212887704372406\n",
      "Epoch: 84, batch: 32, loss: 0.028232021257281303\n",
      "Epoch: 84, batch: 48, loss: 0.021715762093663216\n",
      "Epoch: 84, batch: 64, loss: 0.09665167331695557\n",
      "Epoch: 84, batch: 80, loss: 0.02224396914243698\n",
      "Epoch: 84, batch: 96, loss: 0.028908170759677887\n",
      "Epoch: 84, batch: 112, loss: 0.09533936530351639\n",
      "Epoch: 84, batch: 128, loss: 0.02972976304590702\n",
      "Epoch: 84, batch: 144, loss: 0.07871951162815094\n",
      "Epoch: 85, batch: 0, loss: 0.12797114253044128\n",
      "Epoch: 85, batch: 16, loss: 0.07135885953903198\n",
      "Epoch: 85, batch: 32, loss: 0.02794116735458374\n",
      "Epoch: 85, batch: 48, loss: 0.021386655047535896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85, batch: 64, loss: 0.09589975327253342\n",
      "Epoch: 85, batch: 80, loss: 0.021539121866226196\n",
      "Epoch: 85, batch: 96, loss: 0.028302786871790886\n",
      "Epoch: 85, batch: 112, loss: 0.0947037860751152\n",
      "Epoch: 85, batch: 128, loss: 0.029616350308060646\n",
      "Epoch: 85, batch: 144, loss: 0.07764586806297302\n",
      "Epoch: 86, batch: 0, loss: 0.1283363252878189\n",
      "Epoch: 86, batch: 16, loss: 0.07031819969415665\n",
      "Epoch: 86, batch: 32, loss: 0.027609186246991158\n",
      "Epoch: 86, batch: 48, loss: 0.021073563024401665\n",
      "Epoch: 86, batch: 64, loss: 0.09501703828573227\n",
      "Epoch: 86, batch: 80, loss: 0.020736603066325188\n",
      "Epoch: 86, batch: 96, loss: 0.027683166787028313\n",
      "Epoch: 86, batch: 112, loss: 0.09366672486066818\n",
      "Epoch: 86, batch: 128, loss: 0.02954353392124176\n",
      "Epoch: 86, batch: 144, loss: 0.0763256847858429\n",
      "Epoch: 87, batch: 0, loss: 0.1287267804145813\n",
      "Epoch: 87, batch: 16, loss: 0.06900135427713394\n",
      "Epoch: 87, batch: 32, loss: 0.027327360585331917\n",
      "Epoch: 87, batch: 48, loss: 0.020726824179291725\n",
      "Epoch: 87, batch: 64, loss: 0.09425131231546402\n",
      "Epoch: 87, batch: 80, loss: 0.01993715949356556\n",
      "Epoch: 87, batch: 96, loss: 0.027062540873885155\n",
      "Epoch: 87, batch: 112, loss: 0.09240269660949707\n",
      "Epoch: 87, batch: 128, loss: 0.029594792053103447\n",
      "Epoch: 87, batch: 144, loss: 0.07541272044181824\n",
      "Epoch: 88, batch: 0, loss: 0.12920643389225006\n",
      "Epoch: 88, batch: 16, loss: 0.06768172234296799\n",
      "Epoch: 88, batch: 32, loss: 0.027173416689038277\n",
      "Epoch: 88, batch: 48, loss: 0.02042354643344879\n",
      "Epoch: 88, batch: 64, loss: 0.09329540282487869\n",
      "Epoch: 88, batch: 80, loss: 0.01928083598613739\n",
      "Epoch: 88, batch: 96, loss: 0.02663196437060833\n",
      "Epoch: 88, batch: 112, loss: 0.09148883819580078\n",
      "Epoch: 88, batch: 128, loss: 0.029482023790478706\n",
      "Epoch: 88, batch: 144, loss: 0.07416774332523346\n",
      "Epoch: 89, batch: 0, loss: 0.12995676696300507\n",
      "Epoch: 89, batch: 16, loss: 0.0670226588845253\n",
      "Epoch: 89, batch: 32, loss: 0.027098646387457848\n",
      "Epoch: 89, batch: 48, loss: 0.020213089883327484\n",
      "Epoch: 89, batch: 64, loss: 0.09258604794740677\n",
      "Epoch: 89, batch: 80, loss: 0.018846875056624413\n",
      "Epoch: 89, batch: 96, loss: 0.026263654232025146\n",
      "Epoch: 89, batch: 112, loss: 0.09112149477005005\n",
      "Epoch: 89, batch: 128, loss: 0.029324322938919067\n",
      "Epoch: 89, batch: 144, loss: 0.07314818352460861\n",
      "Epoch: 90, batch: 0, loss: 0.13033625483512878\n",
      "Epoch: 90, batch: 16, loss: 0.06659473478794098\n",
      "Epoch: 90, batch: 32, loss: 0.02680678479373455\n",
      "Epoch: 90, batch: 48, loss: 0.01997305080294609\n",
      "Epoch: 90, batch: 64, loss: 0.09197487682104111\n",
      "Epoch: 90, batch: 80, loss: 0.018307844176888466\n",
      "Epoch: 90, batch: 96, loss: 0.02580091916024685\n",
      "Epoch: 90, batch: 112, loss: 0.09069565683603287\n",
      "Epoch: 90, batch: 128, loss: 0.029206685721874237\n",
      "Epoch: 90, batch: 144, loss: 0.07207150757312775\n",
      "Epoch: 91, batch: 0, loss: 0.13066433370113373\n",
      "Epoch: 91, batch: 16, loss: 0.06579718738794327\n",
      "Epoch: 91, batch: 32, loss: 0.026505209505558014\n",
      "Epoch: 91, batch: 48, loss: 0.019718503579497337\n",
      "Epoch: 91, batch: 64, loss: 0.09116563200950623\n",
      "Epoch: 91, batch: 80, loss: 0.0176802147179842\n",
      "Epoch: 91, batch: 96, loss: 0.025315726175904274\n",
      "Epoch: 91, batch: 112, loss: 0.08991691470146179\n",
      "Epoch: 91, batch: 128, loss: 0.02919900417327881\n",
      "Epoch: 91, batch: 144, loss: 0.07102826982736588\n",
      "Epoch: 92, batch: 0, loss: 0.13101181387901306\n",
      "Epoch: 92, batch: 16, loss: 0.06462441384792328\n",
      "Epoch: 92, batch: 32, loss: 0.026277566328644753\n",
      "Epoch: 92, batch: 48, loss: 0.019473999738693237\n",
      "Epoch: 92, batch: 64, loss: 0.09016674757003784\n",
      "Epoch: 92, batch: 80, loss: 0.017031317576766014\n",
      "Epoch: 92, batch: 96, loss: 0.024893110617995262\n",
      "Epoch: 92, batch: 112, loss: 0.0889258161187172\n",
      "Epoch: 92, batch: 128, loss: 0.029188247397542\n",
      "Epoch: 92, batch: 144, loss: 0.06988050788640976\n",
      "Epoch: 93, batch: 0, loss: 0.13170695304870605\n",
      "Epoch: 93, batch: 16, loss: 0.06368053704500198\n",
      "Epoch: 93, batch: 32, loss: 0.026170877739787102\n",
      "Epoch: 93, batch: 48, loss: 0.019233236089348793\n",
      "Epoch: 93, batch: 64, loss: 0.0895143523812294\n",
      "Epoch: 93, batch: 80, loss: 0.01655210740864277\n",
      "Epoch: 93, batch: 96, loss: 0.024531900882720947\n",
      "Epoch: 93, batch: 112, loss: 0.08811657875776291\n",
      "Epoch: 93, batch: 128, loss: 0.029194338247179985\n",
      "Epoch: 93, batch: 144, loss: 0.06905700266361237\n",
      "Epoch: 94, batch: 0, loss: 0.13199959695339203\n",
      "Epoch: 94, batch: 16, loss: 0.06292860209941864\n",
      "Epoch: 94, batch: 32, loss: 0.02595134638249874\n",
      "Epoch: 94, batch: 48, loss: 0.018959665670990944\n",
      "Epoch: 94, batch: 64, loss: 0.0890764370560646\n",
      "Epoch: 94, batch: 80, loss: 0.016072789207100868\n",
      "Epoch: 94, batch: 96, loss: 0.02412872575223446\n",
      "Epoch: 94, batch: 112, loss: 0.08739293366670609\n",
      "Epoch: 94, batch: 128, loss: 0.02922278456389904\n",
      "Epoch: 94, batch: 144, loss: 0.06832282245159149\n",
      "Epoch: 95, batch: 0, loss: 0.13230818510055542\n",
      "Epoch: 95, batch: 16, loss: 0.06218111887574196\n",
      "Epoch: 95, batch: 32, loss: 0.025758452713489532\n",
      "Epoch: 95, batch: 48, loss: 0.018787788227200508\n",
      "Epoch: 95, batch: 64, loss: 0.08812754601240158\n",
      "Epoch: 95, batch: 80, loss: 0.015612590126693249\n",
      "Epoch: 95, batch: 96, loss: 0.023869618773460388\n",
      "Epoch: 95, batch: 112, loss: 0.08692338317632675\n",
      "Epoch: 95, batch: 128, loss: 0.029055075719952583\n",
      "Epoch: 95, batch: 144, loss: 0.06694721430540085\n",
      "Epoch: 96, batch: 0, loss: 0.13313502073287964\n",
      "Epoch: 96, batch: 16, loss: 0.06187790632247925\n",
      "Epoch: 96, batch: 32, loss: 0.025665869936347008\n",
      "Epoch: 96, batch: 48, loss: 0.01868264377117157\n",
      "Epoch: 96, batch: 64, loss: 0.08735481649637222\n",
      "Epoch: 96, batch: 80, loss: 0.015289290808141232\n",
      "Epoch: 96, batch: 96, loss: 0.02362590841948986\n",
      "Epoch: 96, batch: 112, loss: 0.086774080991745\n",
      "Epoch: 96, batch: 128, loss: 0.028873346745967865\n",
      "Epoch: 96, batch: 144, loss: 0.0658147782087326\n",
      "Epoch: 97, batch: 0, loss: 0.13348336517810822\n",
      "Epoch: 97, batch: 16, loss: 0.06169503927230835\n",
      "Epoch: 97, batch: 32, loss: 0.025384612381458282\n",
      "Epoch: 97, batch: 48, loss: 0.01855330355465412\n",
      "Epoch: 97, batch: 64, loss: 0.08666033297777176\n",
      "Epoch: 97, batch: 80, loss: 0.014881891198456287\n",
      "Epoch: 97, batch: 96, loss: 0.023301132023334503\n",
      "Epoch: 97, batch: 112, loss: 0.0865371897816658\n",
      "Epoch: 97, batch: 128, loss: 0.02873711846768856\n",
      "Epoch: 97, batch: 144, loss: 0.06467363983392715\n",
      "Epoch: 98, batch: 0, loss: 0.13383550941944122\n",
      "Epoch: 98, batch: 16, loss: 0.06117059290409088\n",
      "Epoch: 98, batch: 32, loss: 0.025103287771344185\n",
      "Epoch: 98, batch: 48, loss: 0.01841072179377079\n",
      "Epoch: 98, batch: 64, loss: 0.08584186434745789\n",
      "Epoch: 98, batch: 80, loss: 0.014419756829738617\n",
      "Epoch: 98, batch: 96, loss: 0.022960612550377846\n",
      "Epoch: 98, batch: 112, loss: 0.08598210662603378\n",
      "Epoch: 98, batch: 128, loss: 0.0287216454744339\n",
      "Epoch: 98, batch: 144, loss: 0.06366154551506042\n",
      "Epoch: 99, batch: 0, loss: 0.1341952085494995\n",
      "Epoch: 99, batch: 16, loss: 0.06028057634830475\n",
      "Epoch: 99, batch: 32, loss: 0.024854563176631927\n",
      "Epoch: 99, batch: 48, loss: 0.018208211287856102\n",
      "Epoch: 99, batch: 64, loss: 0.08514418452978134\n",
      "Epoch: 99, batch: 80, loss: 0.013925264589488506\n",
      "Epoch: 99, batch: 96, loss: 0.022629665210843086\n",
      "Epoch: 99, batch: 112, loss: 0.08496838063001633\n",
      "Epoch: 99, batch: 128, loss: 0.028810134157538414\n",
      "Epoch: 99, batch: 144, loss: 0.06280824542045593\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_data.size()[0], batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        x, y = x_data[indices], y_data[indices]\n",
    "        opt.zero_grad()\n",
    "        y_pred=model(x.float())\n",
    "        loss = loss_f(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        print (f'Epoch: {str(epoch)}, batch: {str(i)}, loss: {loss}')\n",
    "duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.365001916885376"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
